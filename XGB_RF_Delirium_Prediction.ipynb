{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGB - RF - Delirium Prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjKdYs1IWUAu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def err_metric(CM): \n",
        "      \n",
        "    TN = CM.iloc[0,0]\n",
        "    FN = CM.iloc[1,0]\n",
        "    TP = CM.iloc[1,1]\n",
        "    FP = CM.iloc[0,1]\n",
        "    precision =(TP)/(TP+FP)\n",
        "    accuracy_model  =(TP+TN)/(TP+TN+FP+FN)\n",
        "    recall_score  =(TP)/(TP+FN)\n",
        "    specificity_value =(TN)/(TN + FP)\n",
        "      \n",
        "    False_positive_rate =(FP)/(FP+TN)\n",
        "    False_negative_rate =(FN)/(FN+TP)\n",
        "    f1_score =2*(( precision * recall_score)/( precision + recall_score))\n",
        "    print(\"Precision value of the model: \",precision)\n",
        "    print(\"Accuracy of the model: \",accuracy_model)\n",
        "    print(\"Recall of the model: \",recall_score)\n",
        "    print(\"Specificity of the model: \",specificity_value)"
      ],
      "metadata": {
        "id": "ADYVCK6OHJ7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delirium_dataset=pd.read_csv('/content/delirium_mimic_dataset_missing_imputed.csv')\n",
        "delirium_dataset.drop('Unnamed: 0',inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "H4gHOTV1Wavk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Encoding"
      ],
      "metadata": {
        "id": "hxHNeQYWaSxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Catboost Encoder"
      ],
      "metadata": {
        "id": "dTXAQoCEew9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delirium_dataset_encoded=delirium_dataset.copy()"
      ],
      "metadata": {
        "id": "DkyfptWYfrxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade category_encoders"
      ],
      "metadata": {
        "id": "PLk_PVfygFVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import category_encoders as ce"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UZVnISNf_md",
        "outputId": "e7a2a64d-5032-4412-b184-b3ba4563db95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbe = ce.CatBoostEncoder(cols=['DISCHARGE_LOCATION'])\n",
        "delirium_dataset_encoded['DISCHARGE_LOCATION'] = cbe.fit_transform(delirium_dataset['DISCHARGE_LOCATION'],delirium_dataset.Delirium)\n",
        "delirium_dataset_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "sZKZenZwfS3q",
        "outputId": "1a2cf42d-8f7f-40ce-9a7a-fa44efbc97cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            AGE         ALT  ART BP Systolic  ART BP mean  ART Lumen Volume  \\\n",
              "0     75.287671   14.625000       110.121564   117.000000          1.776951   \n",
              "1     81.128767   22.000000       115.156716   356.500000          1.227688   \n",
              "2     75.887671   20.666667        94.429669   125.000000          2.300000   \n",
              "3     53.682192   30.333333       117.364350    95.863471          1.781689   \n",
              "4     70.758904   71.000000       129.543340    85.000000          1.691685   \n",
              "...         ...         ...              ...          ...               ...   \n",
              "8641  62.959449  301.757721        93.413793    86.177893          1.705318   \n",
              "8642  72.651520  -55.682184       156.020408    88.023220          1.702226   \n",
              "8643  64.419431  257.347876       109.131148    88.171228          1.704027   \n",
              "8644  56.803376  168.689049       106.333333    85.562593          1.715720   \n",
              "8645  58.191823  235.772172       119.978704    87.592234          1.705197   \n",
              "\n",
              "             AST  Admission Weight (Kg)   Albumin  Alkaline Phosphate  \\\n",
              "0      18.666667              65.284748  1.976923           67.937500   \n",
              "1      30.000000              68.100000  3.350000           83.000000   \n",
              "2      18.500000             106.187923  2.083333          146.833333   \n",
              "3      38.250000              77.877338  3.000000           80.000000   \n",
              "4     113.000000              60.389001  2.050000          102.000000   \n",
              "...          ...                    ...       ...                 ...   \n",
              "8641  148.690843              79.201246  2.761528          128.575455   \n",
              "8642  176.864488              46.921161  2.902954          160.588884   \n",
              "8643  189.495112              71.899354  2.641244          148.622771   \n",
              "8644  113.731382              75.000000  2.893243          165.371832   \n",
              "8645  196.041651              83.828510  2.922918          148.342685   \n",
              "\n",
              "         Ammonia  ...  Pulmonary Artery Pressure mean       RELIGION  \\\n",
              "0      41.896000  ...                       28.120382       CATHOLIC   \n",
              "1    -189.839353  ...                     -382.848191  NOT SPECIFIED   \n",
              "2      53.250487  ...                       29.688995  NOT SPECIFIED   \n",
              "3      44.048273  ...                       27.977587       CATHOLIC   \n",
              "4      44.967481  ...                       30.031274  NOT SPECIFIED   \n",
              "...          ...  ...                             ...            ...   \n",
              "8641   47.687032  ...                       28.143650       CATHOLIC   \n",
              "8642   47.762395  ...                       25.354754       CATHOLIC   \n",
              "8643   47.687032  ...                       27.748658       CATHOLIC   \n",
              "8644   46.691705  ...                       23.000000       CATHOLIC   \n",
              "8645   47.967151  ...                       27.779389       CATHOLIC   \n",
              "\n",
              "      Respiratory Rate  Sodium (serum)  Temperature Celsius  Total Bilirubin  \\\n",
              "0            19.213248      135.831776            36.790870         0.250000   \n",
              "1            16.885154      143.058824            36.490050         0.200000   \n",
              "2            20.700000      140.016129            39.923196         0.200000   \n",
              "3            18.500367      143.695652            37.378148         0.275000   \n",
              "4            19.098462      141.368421            36.629274         0.300000   \n",
              "...                ...             ...                  ...              ...   \n",
              "8641         22.900000      138.000000            35.796296         1.634226   \n",
              "8642         17.406250      135.000000            36.321637         1.800394   \n",
              "8643         16.372881      137.600000            37.399306         1.748749   \n",
              "8644         14.500000      138.700000            36.129641         3.808259   \n",
              "8645         18.647409      137.888889            36.437222         1.772930   \n",
              "\n",
              "      Venous CO2 Pressure  Venous O2 Pressure  Ventilator Tank #1        WBC  \n",
              "0               61.875000           49.875000         2035.542169  10.573626  \n",
              "1               60.500000           40.750000         2156.250000   7.423077  \n",
              "2               49.166667           59.833333         1879.120879  14.581013  \n",
              "3               83.166667           79.666667         1954.705882  13.052500  \n",
              "4               54.000000          172.000000         2391.935484  20.731579  \n",
              "...                   ...                 ...                 ...        ...  \n",
              "8641            48.266947           61.222706         1989.393458   9.775000  \n",
              "8642            48.024201           62.014360         1991.812205   4.140000  \n",
              "8643            48.283297           60.511903         1983.132701   7.700000  \n",
              "8644            47.817090           62.360699         2015.385052   8.014286  \n",
              "8645            47.996948           61.922495         1995.001809   8.700000  \n",
              "\n",
              "[8646 rows x 74 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a896aaa-0d8c-4ebf-98c6-249a7c8ac419\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGE</th>\n",
              "      <th>ALT</th>\n",
              "      <th>ART BP Systolic</th>\n",
              "      <th>ART BP mean</th>\n",
              "      <th>ART Lumen Volume</th>\n",
              "      <th>AST</th>\n",
              "      <th>Admission Weight (Kg)</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Alkaline Phosphate</th>\n",
              "      <th>Ammonia</th>\n",
              "      <th>...</th>\n",
              "      <th>Pulmonary Artery Pressure mean</th>\n",
              "      <th>RELIGION</th>\n",
              "      <th>Respiratory Rate</th>\n",
              "      <th>Sodium (serum)</th>\n",
              "      <th>Temperature Celsius</th>\n",
              "      <th>Total Bilirubin</th>\n",
              "      <th>Venous CO2 Pressure</th>\n",
              "      <th>Venous O2 Pressure</th>\n",
              "      <th>Ventilator Tank #1</th>\n",
              "      <th>WBC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.287671</td>\n",
              "      <td>14.625000</td>\n",
              "      <td>110.121564</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>1.776951</td>\n",
              "      <td>18.666667</td>\n",
              "      <td>65.284748</td>\n",
              "      <td>1.976923</td>\n",
              "      <td>67.937500</td>\n",
              "      <td>41.896000</td>\n",
              "      <td>...</td>\n",
              "      <td>28.120382</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>19.213248</td>\n",
              "      <td>135.831776</td>\n",
              "      <td>36.790870</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>61.875000</td>\n",
              "      <td>49.875000</td>\n",
              "      <td>2035.542169</td>\n",
              "      <td>10.573626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81.128767</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>115.156716</td>\n",
              "      <td>356.500000</td>\n",
              "      <td>1.227688</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>68.100000</td>\n",
              "      <td>3.350000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>-189.839353</td>\n",
              "      <td>...</td>\n",
              "      <td>-382.848191</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>16.885154</td>\n",
              "      <td>143.058824</td>\n",
              "      <td>36.490050</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>60.500000</td>\n",
              "      <td>40.750000</td>\n",
              "      <td>2156.250000</td>\n",
              "      <td>7.423077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>75.887671</td>\n",
              "      <td>20.666667</td>\n",
              "      <td>94.429669</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>106.187923</td>\n",
              "      <td>2.083333</td>\n",
              "      <td>146.833333</td>\n",
              "      <td>53.250487</td>\n",
              "      <td>...</td>\n",
              "      <td>29.688995</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>20.700000</td>\n",
              "      <td>140.016129</td>\n",
              "      <td>39.923196</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>49.166667</td>\n",
              "      <td>59.833333</td>\n",
              "      <td>1879.120879</td>\n",
              "      <td>14.581013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53.682192</td>\n",
              "      <td>30.333333</td>\n",
              "      <td>117.364350</td>\n",
              "      <td>95.863471</td>\n",
              "      <td>1.781689</td>\n",
              "      <td>38.250000</td>\n",
              "      <td>77.877338</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>44.048273</td>\n",
              "      <td>...</td>\n",
              "      <td>27.977587</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>18.500367</td>\n",
              "      <td>143.695652</td>\n",
              "      <td>37.378148</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>83.166667</td>\n",
              "      <td>79.666667</td>\n",
              "      <td>1954.705882</td>\n",
              "      <td>13.052500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>70.758904</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>129.543340</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>1.691685</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>60.389001</td>\n",
              "      <td>2.050000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>44.967481</td>\n",
              "      <td>...</td>\n",
              "      <td>30.031274</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>19.098462</td>\n",
              "      <td>141.368421</td>\n",
              "      <td>36.629274</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>2391.935484</td>\n",
              "      <td>20.731579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8641</th>\n",
              "      <td>62.959449</td>\n",
              "      <td>301.757721</td>\n",
              "      <td>93.413793</td>\n",
              "      <td>86.177893</td>\n",
              "      <td>1.705318</td>\n",
              "      <td>148.690843</td>\n",
              "      <td>79.201246</td>\n",
              "      <td>2.761528</td>\n",
              "      <td>128.575455</td>\n",
              "      <td>47.687032</td>\n",
              "      <td>...</td>\n",
              "      <td>28.143650</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>35.796296</td>\n",
              "      <td>1.634226</td>\n",
              "      <td>48.266947</td>\n",
              "      <td>61.222706</td>\n",
              "      <td>1989.393458</td>\n",
              "      <td>9.775000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8642</th>\n",
              "      <td>72.651520</td>\n",
              "      <td>-55.682184</td>\n",
              "      <td>156.020408</td>\n",
              "      <td>88.023220</td>\n",
              "      <td>1.702226</td>\n",
              "      <td>176.864488</td>\n",
              "      <td>46.921161</td>\n",
              "      <td>2.902954</td>\n",
              "      <td>160.588884</td>\n",
              "      <td>47.762395</td>\n",
              "      <td>...</td>\n",
              "      <td>25.354754</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>17.406250</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>36.321637</td>\n",
              "      <td>1.800394</td>\n",
              "      <td>48.024201</td>\n",
              "      <td>62.014360</td>\n",
              "      <td>1991.812205</td>\n",
              "      <td>4.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8643</th>\n",
              "      <td>64.419431</td>\n",
              "      <td>257.347876</td>\n",
              "      <td>109.131148</td>\n",
              "      <td>88.171228</td>\n",
              "      <td>1.704027</td>\n",
              "      <td>189.495112</td>\n",
              "      <td>71.899354</td>\n",
              "      <td>2.641244</td>\n",
              "      <td>148.622771</td>\n",
              "      <td>47.687032</td>\n",
              "      <td>...</td>\n",
              "      <td>27.748658</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>16.372881</td>\n",
              "      <td>137.600000</td>\n",
              "      <td>37.399306</td>\n",
              "      <td>1.748749</td>\n",
              "      <td>48.283297</td>\n",
              "      <td>60.511903</td>\n",
              "      <td>1983.132701</td>\n",
              "      <td>7.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8644</th>\n",
              "      <td>56.803376</td>\n",
              "      <td>168.689049</td>\n",
              "      <td>106.333333</td>\n",
              "      <td>85.562593</td>\n",
              "      <td>1.715720</td>\n",
              "      <td>113.731382</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>2.893243</td>\n",
              "      <td>165.371832</td>\n",
              "      <td>46.691705</td>\n",
              "      <td>...</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>138.700000</td>\n",
              "      <td>36.129641</td>\n",
              "      <td>3.808259</td>\n",
              "      <td>47.817090</td>\n",
              "      <td>62.360699</td>\n",
              "      <td>2015.385052</td>\n",
              "      <td>8.014286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8645</th>\n",
              "      <td>58.191823</td>\n",
              "      <td>235.772172</td>\n",
              "      <td>119.978704</td>\n",
              "      <td>87.592234</td>\n",
              "      <td>1.705197</td>\n",
              "      <td>196.041651</td>\n",
              "      <td>83.828510</td>\n",
              "      <td>2.922918</td>\n",
              "      <td>148.342685</td>\n",
              "      <td>47.967151</td>\n",
              "      <td>...</td>\n",
              "      <td>27.779389</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>18.647409</td>\n",
              "      <td>137.888889</td>\n",
              "      <td>36.437222</td>\n",
              "      <td>1.772930</td>\n",
              "      <td>47.996948</td>\n",
              "      <td>61.922495</td>\n",
              "      <td>1995.001809</td>\n",
              "      <td>8.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8646 rows × 74 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a896aaa-0d8c-4ebf-98c6-249a7c8ac419')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a896aaa-0d8c-4ebf-98c6-249a7c8ac419 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a896aaa-0d8c-4ebf-98c6-249a7c8ac419');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbe = ce.CatBoostEncoder(cols=['ETHNICITY'])\n",
        "delirium_dataset_encoded['ETHNICITY'] = cbe.fit_transform(delirium_dataset['ETHNICITY'],delirium_dataset.Delirium)\n",
        "delirium_dataset_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "b6OeZvawgb8m",
        "outputId": "1cf3ac87-4c9d-4244-bf87-33df9d00898e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            AGE         ALT  ART BP Systolic  ART BP mean  ART Lumen Volume  \\\n",
              "0     75.287671   14.625000       110.121564   117.000000          1.776951   \n",
              "1     81.128767   22.000000       115.156716   356.500000          1.227688   \n",
              "2     75.887671   20.666667        94.429669   125.000000          2.300000   \n",
              "3     53.682192   30.333333       117.364350    95.863471          1.781689   \n",
              "4     70.758904   71.000000       129.543340    85.000000          1.691685   \n",
              "...         ...         ...              ...          ...               ...   \n",
              "8641  62.959449  301.757721        93.413793    86.177893          1.705318   \n",
              "8642  72.651520  -55.682184       156.020408    88.023220          1.702226   \n",
              "8643  64.419431  257.347876       109.131148    88.171228          1.704027   \n",
              "8644  56.803376  168.689049       106.333333    85.562593          1.715720   \n",
              "8645  58.191823  235.772172       119.978704    87.592234          1.705197   \n",
              "\n",
              "             AST  Admission Weight (Kg)   Albumin  Alkaline Phosphate  \\\n",
              "0      18.666667              65.284748  1.976923           67.937500   \n",
              "1      30.000000              68.100000  3.350000           83.000000   \n",
              "2      18.500000             106.187923  2.083333          146.833333   \n",
              "3      38.250000              77.877338  3.000000           80.000000   \n",
              "4     113.000000              60.389001  2.050000          102.000000   \n",
              "...          ...                    ...       ...                 ...   \n",
              "8641  148.690843              79.201246  2.761528          128.575455   \n",
              "8642  176.864488              46.921161  2.902954          160.588884   \n",
              "8643  189.495112              71.899354  2.641244          148.622771   \n",
              "8644  113.731382              75.000000  2.893243          165.371832   \n",
              "8645  196.041651              83.828510  2.922918          148.342685   \n",
              "\n",
              "         Ammonia  ...  Pulmonary Artery Pressure mean       RELIGION  \\\n",
              "0      41.896000  ...                       28.120382       CATHOLIC   \n",
              "1    -189.839353  ...                     -382.848191  NOT SPECIFIED   \n",
              "2      53.250487  ...                       29.688995  NOT SPECIFIED   \n",
              "3      44.048273  ...                       27.977587       CATHOLIC   \n",
              "4      44.967481  ...                       30.031274  NOT SPECIFIED   \n",
              "...          ...  ...                             ...            ...   \n",
              "8641   47.687032  ...                       28.143650       CATHOLIC   \n",
              "8642   47.762395  ...                       25.354754       CATHOLIC   \n",
              "8643   47.687032  ...                       27.748658       CATHOLIC   \n",
              "8644   46.691705  ...                       23.000000       CATHOLIC   \n",
              "8645   47.967151  ...                       27.779389       CATHOLIC   \n",
              "\n",
              "      Respiratory Rate  Sodium (serum)  Temperature Celsius  Total Bilirubin  \\\n",
              "0            19.213248      135.831776            36.790870         0.250000   \n",
              "1            16.885154      143.058824            36.490050         0.200000   \n",
              "2            20.700000      140.016129            39.923196         0.200000   \n",
              "3            18.500367      143.695652            37.378148         0.275000   \n",
              "4            19.098462      141.368421            36.629274         0.300000   \n",
              "...                ...             ...                  ...              ...   \n",
              "8641         22.900000      138.000000            35.796296         1.634226   \n",
              "8642         17.406250      135.000000            36.321637         1.800394   \n",
              "8643         16.372881      137.600000            37.399306         1.748749   \n",
              "8644         14.500000      138.700000            36.129641         3.808259   \n",
              "8645         18.647409      137.888889            36.437222         1.772930   \n",
              "\n",
              "      Venous CO2 Pressure  Venous O2 Pressure  Ventilator Tank #1        WBC  \n",
              "0               61.875000           49.875000         2035.542169  10.573626  \n",
              "1               60.500000           40.750000         2156.250000   7.423077  \n",
              "2               49.166667           59.833333         1879.120879  14.581013  \n",
              "3               83.166667           79.666667         1954.705882  13.052500  \n",
              "4               54.000000          172.000000         2391.935484  20.731579  \n",
              "...                   ...                 ...                 ...        ...  \n",
              "8641            48.266947           61.222706         1989.393458   9.775000  \n",
              "8642            48.024201           62.014360         1991.812205   4.140000  \n",
              "8643            48.283297           60.511903         1983.132701   7.700000  \n",
              "8644            47.817090           62.360699         2015.385052   8.014286  \n",
              "8645            47.996948           61.922495         1995.001809   8.700000  \n",
              "\n",
              "[8646 rows x 74 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d53839b9-0917-41c6-b30f-ccc70cc6aabc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGE</th>\n",
              "      <th>ALT</th>\n",
              "      <th>ART BP Systolic</th>\n",
              "      <th>ART BP mean</th>\n",
              "      <th>ART Lumen Volume</th>\n",
              "      <th>AST</th>\n",
              "      <th>Admission Weight (Kg)</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Alkaline Phosphate</th>\n",
              "      <th>Ammonia</th>\n",
              "      <th>...</th>\n",
              "      <th>Pulmonary Artery Pressure mean</th>\n",
              "      <th>RELIGION</th>\n",
              "      <th>Respiratory Rate</th>\n",
              "      <th>Sodium (serum)</th>\n",
              "      <th>Temperature Celsius</th>\n",
              "      <th>Total Bilirubin</th>\n",
              "      <th>Venous CO2 Pressure</th>\n",
              "      <th>Venous O2 Pressure</th>\n",
              "      <th>Ventilator Tank #1</th>\n",
              "      <th>WBC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.287671</td>\n",
              "      <td>14.625000</td>\n",
              "      <td>110.121564</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>1.776951</td>\n",
              "      <td>18.666667</td>\n",
              "      <td>65.284748</td>\n",
              "      <td>1.976923</td>\n",
              "      <td>67.937500</td>\n",
              "      <td>41.896000</td>\n",
              "      <td>...</td>\n",
              "      <td>28.120382</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>19.213248</td>\n",
              "      <td>135.831776</td>\n",
              "      <td>36.790870</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>61.875000</td>\n",
              "      <td>49.875000</td>\n",
              "      <td>2035.542169</td>\n",
              "      <td>10.573626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81.128767</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>115.156716</td>\n",
              "      <td>356.500000</td>\n",
              "      <td>1.227688</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>68.100000</td>\n",
              "      <td>3.350000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>-189.839353</td>\n",
              "      <td>...</td>\n",
              "      <td>-382.848191</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>16.885154</td>\n",
              "      <td>143.058824</td>\n",
              "      <td>36.490050</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>60.500000</td>\n",
              "      <td>40.750000</td>\n",
              "      <td>2156.250000</td>\n",
              "      <td>7.423077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>75.887671</td>\n",
              "      <td>20.666667</td>\n",
              "      <td>94.429669</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>106.187923</td>\n",
              "      <td>2.083333</td>\n",
              "      <td>146.833333</td>\n",
              "      <td>53.250487</td>\n",
              "      <td>...</td>\n",
              "      <td>29.688995</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>20.700000</td>\n",
              "      <td>140.016129</td>\n",
              "      <td>39.923196</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>49.166667</td>\n",
              "      <td>59.833333</td>\n",
              "      <td>1879.120879</td>\n",
              "      <td>14.581013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53.682192</td>\n",
              "      <td>30.333333</td>\n",
              "      <td>117.364350</td>\n",
              "      <td>95.863471</td>\n",
              "      <td>1.781689</td>\n",
              "      <td>38.250000</td>\n",
              "      <td>77.877338</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>44.048273</td>\n",
              "      <td>...</td>\n",
              "      <td>27.977587</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>18.500367</td>\n",
              "      <td>143.695652</td>\n",
              "      <td>37.378148</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>83.166667</td>\n",
              "      <td>79.666667</td>\n",
              "      <td>1954.705882</td>\n",
              "      <td>13.052500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>70.758904</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>129.543340</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>1.691685</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>60.389001</td>\n",
              "      <td>2.050000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>44.967481</td>\n",
              "      <td>...</td>\n",
              "      <td>30.031274</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>19.098462</td>\n",
              "      <td>141.368421</td>\n",
              "      <td>36.629274</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>2391.935484</td>\n",
              "      <td>20.731579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8641</th>\n",
              "      <td>62.959449</td>\n",
              "      <td>301.757721</td>\n",
              "      <td>93.413793</td>\n",
              "      <td>86.177893</td>\n",
              "      <td>1.705318</td>\n",
              "      <td>148.690843</td>\n",
              "      <td>79.201246</td>\n",
              "      <td>2.761528</td>\n",
              "      <td>128.575455</td>\n",
              "      <td>47.687032</td>\n",
              "      <td>...</td>\n",
              "      <td>28.143650</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>35.796296</td>\n",
              "      <td>1.634226</td>\n",
              "      <td>48.266947</td>\n",
              "      <td>61.222706</td>\n",
              "      <td>1989.393458</td>\n",
              "      <td>9.775000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8642</th>\n",
              "      <td>72.651520</td>\n",
              "      <td>-55.682184</td>\n",
              "      <td>156.020408</td>\n",
              "      <td>88.023220</td>\n",
              "      <td>1.702226</td>\n",
              "      <td>176.864488</td>\n",
              "      <td>46.921161</td>\n",
              "      <td>2.902954</td>\n",
              "      <td>160.588884</td>\n",
              "      <td>47.762395</td>\n",
              "      <td>...</td>\n",
              "      <td>25.354754</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>17.406250</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>36.321637</td>\n",
              "      <td>1.800394</td>\n",
              "      <td>48.024201</td>\n",
              "      <td>62.014360</td>\n",
              "      <td>1991.812205</td>\n",
              "      <td>4.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8643</th>\n",
              "      <td>64.419431</td>\n",
              "      <td>257.347876</td>\n",
              "      <td>109.131148</td>\n",
              "      <td>88.171228</td>\n",
              "      <td>1.704027</td>\n",
              "      <td>189.495112</td>\n",
              "      <td>71.899354</td>\n",
              "      <td>2.641244</td>\n",
              "      <td>148.622771</td>\n",
              "      <td>47.687032</td>\n",
              "      <td>...</td>\n",
              "      <td>27.748658</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>16.372881</td>\n",
              "      <td>137.600000</td>\n",
              "      <td>37.399306</td>\n",
              "      <td>1.748749</td>\n",
              "      <td>48.283297</td>\n",
              "      <td>60.511903</td>\n",
              "      <td>1983.132701</td>\n",
              "      <td>7.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8644</th>\n",
              "      <td>56.803376</td>\n",
              "      <td>168.689049</td>\n",
              "      <td>106.333333</td>\n",
              "      <td>85.562593</td>\n",
              "      <td>1.715720</td>\n",
              "      <td>113.731382</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>2.893243</td>\n",
              "      <td>165.371832</td>\n",
              "      <td>46.691705</td>\n",
              "      <td>...</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>138.700000</td>\n",
              "      <td>36.129641</td>\n",
              "      <td>3.808259</td>\n",
              "      <td>47.817090</td>\n",
              "      <td>62.360699</td>\n",
              "      <td>2015.385052</td>\n",
              "      <td>8.014286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8645</th>\n",
              "      <td>58.191823</td>\n",
              "      <td>235.772172</td>\n",
              "      <td>119.978704</td>\n",
              "      <td>87.592234</td>\n",
              "      <td>1.705197</td>\n",
              "      <td>196.041651</td>\n",
              "      <td>83.828510</td>\n",
              "      <td>2.922918</td>\n",
              "      <td>148.342685</td>\n",
              "      <td>47.967151</td>\n",
              "      <td>...</td>\n",
              "      <td>27.779389</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>18.647409</td>\n",
              "      <td>137.888889</td>\n",
              "      <td>36.437222</td>\n",
              "      <td>1.772930</td>\n",
              "      <td>47.996948</td>\n",
              "      <td>61.922495</td>\n",
              "      <td>1995.001809</td>\n",
              "      <td>8.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8646 rows × 74 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d53839b9-0917-41c6-b30f-ccc70cc6aabc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d53839b9-0917-41c6-b30f-ccc70cc6aabc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d53839b9-0917-41c6-b30f-ccc70cc6aabc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbe = ce.CatBoostEncoder(cols=['INSURANCE'])\n",
        "delirium_dataset_encoded['INSURANCE'] = cbe.fit_transform(delirium_dataset['INSURANCE'],delirium_dataset.Delirium)\n",
        "delirium_dataset_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "MyBekh-VgfcC",
        "outputId": "9a79e387-f3c0-4ac1-a365-e5103b0c2852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            AGE         ALT  ART BP Systolic  ART BP mean  ART Lumen Volume  \\\n",
              "0     75.287671   14.625000       110.121564   117.000000          1.776951   \n",
              "1     81.128767   22.000000       115.156716   356.500000          1.227688   \n",
              "2     75.887671   20.666667        94.429669   125.000000          2.300000   \n",
              "3     53.682192   30.333333       117.364350    95.863471          1.781689   \n",
              "4     70.758904   71.000000       129.543340    85.000000          1.691685   \n",
              "...         ...         ...              ...          ...               ...   \n",
              "8641  62.959449  301.757721        93.413793    86.177893          1.705318   \n",
              "8642  72.651520  -55.682184       156.020408    88.023220          1.702226   \n",
              "8643  64.419431  257.347876       109.131148    88.171228          1.704027   \n",
              "8644  56.803376  168.689049       106.333333    85.562593          1.715720   \n",
              "8645  58.191823  235.772172       119.978704    87.592234          1.705197   \n",
              "\n",
              "             AST  Admission Weight (Kg)   Albumin  Alkaline Phosphate  \\\n",
              "0      18.666667              65.284748  1.976923           67.937500   \n",
              "1      30.000000              68.100000  3.350000           83.000000   \n",
              "2      18.500000             106.187923  2.083333          146.833333   \n",
              "3      38.250000              77.877338  3.000000           80.000000   \n",
              "4     113.000000              60.389001  2.050000          102.000000   \n",
              "...          ...                    ...       ...                 ...   \n",
              "8641  148.690843              79.201246  2.761528          128.575455   \n",
              "8642  176.864488              46.921161  2.902954          160.588884   \n",
              "8643  189.495112              71.899354  2.641244          148.622771   \n",
              "8644  113.731382              75.000000  2.893243          165.371832   \n",
              "8645  196.041651              83.828510  2.922918          148.342685   \n",
              "\n",
              "         Ammonia  ...  Pulmonary Artery Pressure mean       RELIGION  \\\n",
              "0      41.896000  ...                       28.120382       CATHOLIC   \n",
              "1    -189.839353  ...                     -382.848191  NOT SPECIFIED   \n",
              "2      53.250487  ...                       29.688995  NOT SPECIFIED   \n",
              "3      44.048273  ...                       27.977587       CATHOLIC   \n",
              "4      44.967481  ...                       30.031274  NOT SPECIFIED   \n",
              "...          ...  ...                             ...            ...   \n",
              "8641   47.687032  ...                       28.143650       CATHOLIC   \n",
              "8642   47.762395  ...                       25.354754       CATHOLIC   \n",
              "8643   47.687032  ...                       27.748658       CATHOLIC   \n",
              "8644   46.691705  ...                       23.000000       CATHOLIC   \n",
              "8645   47.967151  ...                       27.779389       CATHOLIC   \n",
              "\n",
              "      Respiratory Rate  Sodium (serum)  Temperature Celsius  Total Bilirubin  \\\n",
              "0            19.213248      135.831776            36.790870         0.250000   \n",
              "1            16.885154      143.058824            36.490050         0.200000   \n",
              "2            20.700000      140.016129            39.923196         0.200000   \n",
              "3            18.500367      143.695652            37.378148         0.275000   \n",
              "4            19.098462      141.368421            36.629274         0.300000   \n",
              "...                ...             ...                  ...              ...   \n",
              "8641         22.900000      138.000000            35.796296         1.634226   \n",
              "8642         17.406250      135.000000            36.321637         1.800394   \n",
              "8643         16.372881      137.600000            37.399306         1.748749   \n",
              "8644         14.500000      138.700000            36.129641         3.808259   \n",
              "8645         18.647409      137.888889            36.437222         1.772930   \n",
              "\n",
              "      Venous CO2 Pressure  Venous O2 Pressure  Ventilator Tank #1        WBC  \n",
              "0               61.875000           49.875000         2035.542169  10.573626  \n",
              "1               60.500000           40.750000         2156.250000   7.423077  \n",
              "2               49.166667           59.833333         1879.120879  14.581013  \n",
              "3               83.166667           79.666667         1954.705882  13.052500  \n",
              "4               54.000000          172.000000         2391.935484  20.731579  \n",
              "...                   ...                 ...                 ...        ...  \n",
              "8641            48.266947           61.222706         1989.393458   9.775000  \n",
              "8642            48.024201           62.014360         1991.812205   4.140000  \n",
              "8643            48.283297           60.511903         1983.132701   7.700000  \n",
              "8644            47.817090           62.360699         2015.385052   8.014286  \n",
              "8645            47.996948           61.922495         1995.001809   8.700000  \n",
              "\n",
              "[8646 rows x 74 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02c8af08-d64c-4d81-b7c8-d4f256d1b5e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGE</th>\n",
              "      <th>ALT</th>\n",
              "      <th>ART BP Systolic</th>\n",
              "      <th>ART BP mean</th>\n",
              "      <th>ART Lumen Volume</th>\n",
              "      <th>AST</th>\n",
              "      <th>Admission Weight (Kg)</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Alkaline Phosphate</th>\n",
              "      <th>Ammonia</th>\n",
              "      <th>...</th>\n",
              "      <th>Pulmonary Artery Pressure mean</th>\n",
              "      <th>RELIGION</th>\n",
              "      <th>Respiratory Rate</th>\n",
              "      <th>Sodium (serum)</th>\n",
              "      <th>Temperature Celsius</th>\n",
              "      <th>Total Bilirubin</th>\n",
              "      <th>Venous CO2 Pressure</th>\n",
              "      <th>Venous O2 Pressure</th>\n",
              "      <th>Ventilator Tank #1</th>\n",
              "      <th>WBC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.287671</td>\n",
              "      <td>14.625000</td>\n",
              "      <td>110.121564</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>1.776951</td>\n",
              "      <td>18.666667</td>\n",
              "      <td>65.284748</td>\n",
              "      <td>1.976923</td>\n",
              "      <td>67.937500</td>\n",
              "      <td>41.896000</td>\n",
              "      <td>...</td>\n",
              "      <td>28.120382</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>19.213248</td>\n",
              "      <td>135.831776</td>\n",
              "      <td>36.790870</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>61.875000</td>\n",
              "      <td>49.875000</td>\n",
              "      <td>2035.542169</td>\n",
              "      <td>10.573626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81.128767</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>115.156716</td>\n",
              "      <td>356.500000</td>\n",
              "      <td>1.227688</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>68.100000</td>\n",
              "      <td>3.350000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>-189.839353</td>\n",
              "      <td>...</td>\n",
              "      <td>-382.848191</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>16.885154</td>\n",
              "      <td>143.058824</td>\n",
              "      <td>36.490050</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>60.500000</td>\n",
              "      <td>40.750000</td>\n",
              "      <td>2156.250000</td>\n",
              "      <td>7.423077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>75.887671</td>\n",
              "      <td>20.666667</td>\n",
              "      <td>94.429669</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>106.187923</td>\n",
              "      <td>2.083333</td>\n",
              "      <td>146.833333</td>\n",
              "      <td>53.250487</td>\n",
              "      <td>...</td>\n",
              "      <td>29.688995</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>20.700000</td>\n",
              "      <td>140.016129</td>\n",
              "      <td>39.923196</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>49.166667</td>\n",
              "      <td>59.833333</td>\n",
              "      <td>1879.120879</td>\n",
              "      <td>14.581013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53.682192</td>\n",
              "      <td>30.333333</td>\n",
              "      <td>117.364350</td>\n",
              "      <td>95.863471</td>\n",
              "      <td>1.781689</td>\n",
              "      <td>38.250000</td>\n",
              "      <td>77.877338</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>44.048273</td>\n",
              "      <td>...</td>\n",
              "      <td>27.977587</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>18.500367</td>\n",
              "      <td>143.695652</td>\n",
              "      <td>37.378148</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>83.166667</td>\n",
              "      <td>79.666667</td>\n",
              "      <td>1954.705882</td>\n",
              "      <td>13.052500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>70.758904</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>129.543340</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>1.691685</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>60.389001</td>\n",
              "      <td>2.050000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>44.967481</td>\n",
              "      <td>...</td>\n",
              "      <td>30.031274</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>19.098462</td>\n",
              "      <td>141.368421</td>\n",
              "      <td>36.629274</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>2391.935484</td>\n",
              "      <td>20.731579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8641</th>\n",
              "      <td>62.959449</td>\n",
              "      <td>301.757721</td>\n",
              "      <td>93.413793</td>\n",
              "      <td>86.177893</td>\n",
              "      <td>1.705318</td>\n",
              "      <td>148.690843</td>\n",
              "      <td>79.201246</td>\n",
              "      <td>2.761528</td>\n",
              "      <td>128.575455</td>\n",
              "      <td>47.687032</td>\n",
              "      <td>...</td>\n",
              "      <td>28.143650</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>35.796296</td>\n",
              "      <td>1.634226</td>\n",
              "      <td>48.266947</td>\n",
              "      <td>61.222706</td>\n",
              "      <td>1989.393458</td>\n",
              "      <td>9.775000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8642</th>\n",
              "      <td>72.651520</td>\n",
              "      <td>-55.682184</td>\n",
              "      <td>156.020408</td>\n",
              "      <td>88.023220</td>\n",
              "      <td>1.702226</td>\n",
              "      <td>176.864488</td>\n",
              "      <td>46.921161</td>\n",
              "      <td>2.902954</td>\n",
              "      <td>160.588884</td>\n",
              "      <td>47.762395</td>\n",
              "      <td>...</td>\n",
              "      <td>25.354754</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>17.406250</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>36.321637</td>\n",
              "      <td>1.800394</td>\n",
              "      <td>48.024201</td>\n",
              "      <td>62.014360</td>\n",
              "      <td>1991.812205</td>\n",
              "      <td>4.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8643</th>\n",
              "      <td>64.419431</td>\n",
              "      <td>257.347876</td>\n",
              "      <td>109.131148</td>\n",
              "      <td>88.171228</td>\n",
              "      <td>1.704027</td>\n",
              "      <td>189.495112</td>\n",
              "      <td>71.899354</td>\n",
              "      <td>2.641244</td>\n",
              "      <td>148.622771</td>\n",
              "      <td>47.687032</td>\n",
              "      <td>...</td>\n",
              "      <td>27.748658</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>16.372881</td>\n",
              "      <td>137.600000</td>\n",
              "      <td>37.399306</td>\n",
              "      <td>1.748749</td>\n",
              "      <td>48.283297</td>\n",
              "      <td>60.511903</td>\n",
              "      <td>1983.132701</td>\n",
              "      <td>7.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8644</th>\n",
              "      <td>56.803376</td>\n",
              "      <td>168.689049</td>\n",
              "      <td>106.333333</td>\n",
              "      <td>85.562593</td>\n",
              "      <td>1.715720</td>\n",
              "      <td>113.731382</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>2.893243</td>\n",
              "      <td>165.371832</td>\n",
              "      <td>46.691705</td>\n",
              "      <td>...</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>138.700000</td>\n",
              "      <td>36.129641</td>\n",
              "      <td>3.808259</td>\n",
              "      <td>47.817090</td>\n",
              "      <td>62.360699</td>\n",
              "      <td>2015.385052</td>\n",
              "      <td>8.014286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8645</th>\n",
              "      <td>58.191823</td>\n",
              "      <td>235.772172</td>\n",
              "      <td>119.978704</td>\n",
              "      <td>87.592234</td>\n",
              "      <td>1.705197</td>\n",
              "      <td>196.041651</td>\n",
              "      <td>83.828510</td>\n",
              "      <td>2.922918</td>\n",
              "      <td>148.342685</td>\n",
              "      <td>47.967151</td>\n",
              "      <td>...</td>\n",
              "      <td>27.779389</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>18.647409</td>\n",
              "      <td>137.888889</td>\n",
              "      <td>36.437222</td>\n",
              "      <td>1.772930</td>\n",
              "      <td>47.996948</td>\n",
              "      <td>61.922495</td>\n",
              "      <td>1995.001809</td>\n",
              "      <td>8.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8646 rows × 74 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02c8af08-d64c-4d81-b7c8-d4f256d1b5e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02c8af08-d64c-4d81-b7c8-d4f256d1b5e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02c8af08-d64c-4d81-b7c8-d4f256d1b5e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbe = ce.CatBoostEncoder(cols=['LANGUAGE'])\n",
        "delirium_dataset_encoded['LANGUAGE'] = cbe.fit_transform(delirium_dataset['LANGUAGE'],delirium_dataset.Delirium)\n",
        "delirium_dataset_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "8zyKqlDvgjO-",
        "outputId": "7ec2d9d6-1e7e-4e73-afe5-a7090aa613b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            AGE         ALT  ART BP Systolic  ART BP mean  ART Lumen Volume  \\\n",
              "0     75.287671   14.625000       110.121564   117.000000          1.776951   \n",
              "1     81.128767   22.000000       115.156716   356.500000          1.227688   \n",
              "2     75.887671   20.666667        94.429669   125.000000          2.300000   \n",
              "3     53.682192   30.333333       117.364350    95.863471          1.781689   \n",
              "4     70.758904   71.000000       129.543340    85.000000          1.691685   \n",
              "...         ...         ...              ...          ...               ...   \n",
              "8641  62.959449  301.757721        93.413793    86.177893          1.705318   \n",
              "8642  72.651520  -55.682184       156.020408    88.023220          1.702226   \n",
              "8643  64.419431  257.347876       109.131148    88.171228          1.704027   \n",
              "8644  56.803376  168.689049       106.333333    85.562593          1.715720   \n",
              "8645  58.191823  235.772172       119.978704    87.592234          1.705197   \n",
              "\n",
              "             AST  Admission Weight (Kg)   Albumin  Alkaline Phosphate  \\\n",
              "0      18.666667              65.284748  1.976923           67.937500   \n",
              "1      30.000000              68.100000  3.350000           83.000000   \n",
              "2      18.500000             106.187923  2.083333          146.833333   \n",
              "3      38.250000              77.877338  3.000000           80.000000   \n",
              "4     113.000000              60.389001  2.050000          102.000000   \n",
              "...          ...                    ...       ...                 ...   \n",
              "8641  148.690843              79.201246  2.761528          128.575455   \n",
              "8642  176.864488              46.921161  2.902954          160.588884   \n",
              "8643  189.495112              71.899354  2.641244          148.622771   \n",
              "8644  113.731382              75.000000  2.893243          165.371832   \n",
              "8645  196.041651              83.828510  2.922918          148.342685   \n",
              "\n",
              "         Ammonia  ...  Pulmonary Artery Pressure mean       RELIGION  \\\n",
              "0      41.896000  ...                       28.120382       CATHOLIC   \n",
              "1    -189.839353  ...                     -382.848191  NOT SPECIFIED   \n",
              "2      53.250487  ...                       29.688995  NOT SPECIFIED   \n",
              "3      44.048273  ...                       27.977587       CATHOLIC   \n",
              "4      44.967481  ...                       30.031274  NOT SPECIFIED   \n",
              "...          ...  ...                             ...            ...   \n",
              "8641   47.687032  ...                       28.143650       CATHOLIC   \n",
              "8642   47.762395  ...                       25.354754       CATHOLIC   \n",
              "8643   47.687032  ...                       27.748658       CATHOLIC   \n",
              "8644   46.691705  ...                       23.000000       CATHOLIC   \n",
              "8645   47.967151  ...                       27.779389       CATHOLIC   \n",
              "\n",
              "      Respiratory Rate  Sodium (serum)  Temperature Celsius  Total Bilirubin  \\\n",
              "0            19.213248      135.831776            36.790870         0.250000   \n",
              "1            16.885154      143.058824            36.490050         0.200000   \n",
              "2            20.700000      140.016129            39.923196         0.200000   \n",
              "3            18.500367      143.695652            37.378148         0.275000   \n",
              "4            19.098462      141.368421            36.629274         0.300000   \n",
              "...                ...             ...                  ...              ...   \n",
              "8641         22.900000      138.000000            35.796296         1.634226   \n",
              "8642         17.406250      135.000000            36.321637         1.800394   \n",
              "8643         16.372881      137.600000            37.399306         1.748749   \n",
              "8644         14.500000      138.700000            36.129641         3.808259   \n",
              "8645         18.647409      137.888889            36.437222         1.772930   \n",
              "\n",
              "      Venous CO2 Pressure  Venous O2 Pressure  Ventilator Tank #1        WBC  \n",
              "0               61.875000           49.875000         2035.542169  10.573626  \n",
              "1               60.500000           40.750000         2156.250000   7.423077  \n",
              "2               49.166667           59.833333         1879.120879  14.581013  \n",
              "3               83.166667           79.666667         1954.705882  13.052500  \n",
              "4               54.000000          172.000000         2391.935484  20.731579  \n",
              "...                   ...                 ...                 ...        ...  \n",
              "8641            48.266947           61.222706         1989.393458   9.775000  \n",
              "8642            48.024201           62.014360         1991.812205   4.140000  \n",
              "8643            48.283297           60.511903         1983.132701   7.700000  \n",
              "8644            47.817090           62.360699         2015.385052   8.014286  \n",
              "8645            47.996948           61.922495         1995.001809   8.700000  \n",
              "\n",
              "[8646 rows x 74 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad282d95-78d2-47bc-9a6c-6b11dc4c0954\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGE</th>\n",
              "      <th>ALT</th>\n",
              "      <th>ART BP Systolic</th>\n",
              "      <th>ART BP mean</th>\n",
              "      <th>ART Lumen Volume</th>\n",
              "      <th>AST</th>\n",
              "      <th>Admission Weight (Kg)</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Alkaline Phosphate</th>\n",
              "      <th>Ammonia</th>\n",
              "      <th>...</th>\n",
              "      <th>Pulmonary Artery Pressure mean</th>\n",
              "      <th>RELIGION</th>\n",
              "      <th>Respiratory Rate</th>\n",
              "      <th>Sodium (serum)</th>\n",
              "      <th>Temperature Celsius</th>\n",
              "      <th>Total Bilirubin</th>\n",
              "      <th>Venous CO2 Pressure</th>\n",
              "      <th>Venous O2 Pressure</th>\n",
              "      <th>Ventilator Tank #1</th>\n",
              "      <th>WBC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.287671</td>\n",
              "      <td>14.625000</td>\n",
              "      <td>110.121564</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>1.776951</td>\n",
              "      <td>18.666667</td>\n",
              "      <td>65.284748</td>\n",
              "      <td>1.976923</td>\n",
              "      <td>67.937500</td>\n",
              "      <td>41.896000</td>\n",
              "      <td>...</td>\n",
              "      <td>28.120382</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>19.213248</td>\n",
              "      <td>135.831776</td>\n",
              "      <td>36.790870</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>61.875000</td>\n",
              "      <td>49.875000</td>\n",
              "      <td>2035.542169</td>\n",
              "      <td>10.573626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81.128767</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>115.156716</td>\n",
              "      <td>356.500000</td>\n",
              "      <td>1.227688</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>68.100000</td>\n",
              "      <td>3.350000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>-189.839353</td>\n",
              "      <td>...</td>\n",
              "      <td>-382.848191</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>16.885154</td>\n",
              "      <td>143.058824</td>\n",
              "      <td>36.490050</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>60.500000</td>\n",
              "      <td>40.750000</td>\n",
              "      <td>2156.250000</td>\n",
              "      <td>7.423077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>75.887671</td>\n",
              "      <td>20.666667</td>\n",
              "      <td>94.429669</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>106.187923</td>\n",
              "      <td>2.083333</td>\n",
              "      <td>146.833333</td>\n",
              "      <td>53.250487</td>\n",
              "      <td>...</td>\n",
              "      <td>29.688995</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>20.700000</td>\n",
              "      <td>140.016129</td>\n",
              "      <td>39.923196</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>49.166667</td>\n",
              "      <td>59.833333</td>\n",
              "      <td>1879.120879</td>\n",
              "      <td>14.581013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53.682192</td>\n",
              "      <td>30.333333</td>\n",
              "      <td>117.364350</td>\n",
              "      <td>95.863471</td>\n",
              "      <td>1.781689</td>\n",
              "      <td>38.250000</td>\n",
              "      <td>77.877338</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>44.048273</td>\n",
              "      <td>...</td>\n",
              "      <td>27.977587</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>18.500367</td>\n",
              "      <td>143.695652</td>\n",
              "      <td>37.378148</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>83.166667</td>\n",
              "      <td>79.666667</td>\n",
              "      <td>1954.705882</td>\n",
              "      <td>13.052500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>70.758904</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>129.543340</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>1.691685</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>60.389001</td>\n",
              "      <td>2.050000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>44.967481</td>\n",
              "      <td>...</td>\n",
              "      <td>30.031274</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>19.098462</td>\n",
              "      <td>141.368421</td>\n",
              "      <td>36.629274</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>2391.935484</td>\n",
              "      <td>20.731579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8641</th>\n",
              "      <td>62.959449</td>\n",
              "      <td>301.757721</td>\n",
              "      <td>93.413793</td>\n",
              "      <td>86.177893</td>\n",
              "      <td>1.705318</td>\n",
              "      <td>148.690843</td>\n",
              "      <td>79.201246</td>\n",
              "      <td>2.761528</td>\n",
              "      <td>128.575455</td>\n",
              "      <td>47.687032</td>\n",
              "      <td>...</td>\n",
              "      <td>28.143650</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>35.796296</td>\n",
              "      <td>1.634226</td>\n",
              "      <td>48.266947</td>\n",
              "      <td>61.222706</td>\n",
              "      <td>1989.393458</td>\n",
              "      <td>9.775000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8642</th>\n",
              "      <td>72.651520</td>\n",
              "      <td>-55.682184</td>\n",
              "      <td>156.020408</td>\n",
              "      <td>88.023220</td>\n",
              "      <td>1.702226</td>\n",
              "      <td>176.864488</td>\n",
              "      <td>46.921161</td>\n",
              "      <td>2.902954</td>\n",
              "      <td>160.588884</td>\n",
              "      <td>47.762395</td>\n",
              "      <td>...</td>\n",
              "      <td>25.354754</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>17.406250</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>36.321637</td>\n",
              "      <td>1.800394</td>\n",
              "      <td>48.024201</td>\n",
              "      <td>62.014360</td>\n",
              "      <td>1991.812205</td>\n",
              "      <td>4.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8643</th>\n",
              "      <td>64.419431</td>\n",
              "      <td>257.347876</td>\n",
              "      <td>109.131148</td>\n",
              "      <td>88.171228</td>\n",
              "      <td>1.704027</td>\n",
              "      <td>189.495112</td>\n",
              "      <td>71.899354</td>\n",
              "      <td>2.641244</td>\n",
              "      <td>148.622771</td>\n",
              "      <td>47.687032</td>\n",
              "      <td>...</td>\n",
              "      <td>27.748658</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>16.372881</td>\n",
              "      <td>137.600000</td>\n",
              "      <td>37.399306</td>\n",
              "      <td>1.748749</td>\n",
              "      <td>48.283297</td>\n",
              "      <td>60.511903</td>\n",
              "      <td>1983.132701</td>\n",
              "      <td>7.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8644</th>\n",
              "      <td>56.803376</td>\n",
              "      <td>168.689049</td>\n",
              "      <td>106.333333</td>\n",
              "      <td>85.562593</td>\n",
              "      <td>1.715720</td>\n",
              "      <td>113.731382</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>2.893243</td>\n",
              "      <td>165.371832</td>\n",
              "      <td>46.691705</td>\n",
              "      <td>...</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>138.700000</td>\n",
              "      <td>36.129641</td>\n",
              "      <td>3.808259</td>\n",
              "      <td>47.817090</td>\n",
              "      <td>62.360699</td>\n",
              "      <td>2015.385052</td>\n",
              "      <td>8.014286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8645</th>\n",
              "      <td>58.191823</td>\n",
              "      <td>235.772172</td>\n",
              "      <td>119.978704</td>\n",
              "      <td>87.592234</td>\n",
              "      <td>1.705197</td>\n",
              "      <td>196.041651</td>\n",
              "      <td>83.828510</td>\n",
              "      <td>2.922918</td>\n",
              "      <td>148.342685</td>\n",
              "      <td>47.967151</td>\n",
              "      <td>...</td>\n",
              "      <td>27.779389</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>18.647409</td>\n",
              "      <td>137.888889</td>\n",
              "      <td>36.437222</td>\n",
              "      <td>1.772930</td>\n",
              "      <td>47.996948</td>\n",
              "      <td>61.922495</td>\n",
              "      <td>1995.001809</td>\n",
              "      <td>8.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8646 rows × 74 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad282d95-78d2-47bc-9a6c-6b11dc4c0954')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad282d95-78d2-47bc-9a6c-6b11dc4c0954 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad282d95-78d2-47bc-9a6c-6b11dc4c0954');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbe = ce.CatBoostEncoder(cols=['MARITAL_STATUS'])\n",
        "delirium_dataset_encoded['MARITAL_STATUS'] = cbe.fit_transform(delirium_dataset['MARITAL_STATUS'],delirium_dataset.Delirium)\n",
        "delirium_dataset_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "Un1guXW-gnAg",
        "outputId": "9656320b-b870-43cc-ae8f-6db1e0cbe356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            AGE         ALT  ART BP Systolic  ART BP mean  ART Lumen Volume  \\\n",
              "0     75.287671   14.625000       110.121564   117.000000          1.776951   \n",
              "1     81.128767   22.000000       115.156716   356.500000          1.227688   \n",
              "2     75.887671   20.666667        94.429669   125.000000          2.300000   \n",
              "3     53.682192   30.333333       117.364350    95.863471          1.781689   \n",
              "4     70.758904   71.000000       129.543340    85.000000          1.691685   \n",
              "...         ...         ...              ...          ...               ...   \n",
              "8641  62.959449  301.757721        93.413793    86.177893          1.705318   \n",
              "8642  72.651520  -55.682184       156.020408    88.023220          1.702226   \n",
              "8643  64.419431  257.347876       109.131148    88.171228          1.704027   \n",
              "8644  56.803376  168.689049       106.333333    85.562593          1.715720   \n",
              "8645  58.191823  235.772172       119.978704    87.592234          1.705197   \n",
              "\n",
              "             AST  Admission Weight (Kg)   Albumin  Alkaline Phosphate  \\\n",
              "0      18.666667              65.284748  1.976923           67.937500   \n",
              "1      30.000000              68.100000  3.350000           83.000000   \n",
              "2      18.500000             106.187923  2.083333          146.833333   \n",
              "3      38.250000              77.877338  3.000000           80.000000   \n",
              "4     113.000000              60.389001  2.050000          102.000000   \n",
              "...          ...                    ...       ...                 ...   \n",
              "8641  148.690843              79.201246  2.761528          128.575455   \n",
              "8642  176.864488              46.921161  2.902954          160.588884   \n",
              "8643  189.495112              71.899354  2.641244          148.622771   \n",
              "8644  113.731382              75.000000  2.893243          165.371832   \n",
              "8645  196.041651              83.828510  2.922918          148.342685   \n",
              "\n",
              "         Ammonia  ...  Pulmonary Artery Pressure mean       RELIGION  \\\n",
              "0      41.896000  ...                       28.120382       CATHOLIC   \n",
              "1    -189.839353  ...                     -382.848191  NOT SPECIFIED   \n",
              "2      53.250487  ...                       29.688995  NOT SPECIFIED   \n",
              "3      44.048273  ...                       27.977587       CATHOLIC   \n",
              "4      44.967481  ...                       30.031274  NOT SPECIFIED   \n",
              "...          ...  ...                             ...            ...   \n",
              "8641   47.687032  ...                       28.143650       CATHOLIC   \n",
              "8642   47.762395  ...                       25.354754       CATHOLIC   \n",
              "8643   47.687032  ...                       27.748658       CATHOLIC   \n",
              "8644   46.691705  ...                       23.000000       CATHOLIC   \n",
              "8645   47.967151  ...                       27.779389       CATHOLIC   \n",
              "\n",
              "      Respiratory Rate  Sodium (serum)  Temperature Celsius  Total Bilirubin  \\\n",
              "0            19.213248      135.831776            36.790870         0.250000   \n",
              "1            16.885154      143.058824            36.490050         0.200000   \n",
              "2            20.700000      140.016129            39.923196         0.200000   \n",
              "3            18.500367      143.695652            37.378148         0.275000   \n",
              "4            19.098462      141.368421            36.629274         0.300000   \n",
              "...                ...             ...                  ...              ...   \n",
              "8641         22.900000      138.000000            35.796296         1.634226   \n",
              "8642         17.406250      135.000000            36.321637         1.800394   \n",
              "8643         16.372881      137.600000            37.399306         1.748749   \n",
              "8644         14.500000      138.700000            36.129641         3.808259   \n",
              "8645         18.647409      137.888889            36.437222         1.772930   \n",
              "\n",
              "      Venous CO2 Pressure  Venous O2 Pressure  Ventilator Tank #1        WBC  \n",
              "0               61.875000           49.875000         2035.542169  10.573626  \n",
              "1               60.500000           40.750000         2156.250000   7.423077  \n",
              "2               49.166667           59.833333         1879.120879  14.581013  \n",
              "3               83.166667           79.666667         1954.705882  13.052500  \n",
              "4               54.000000          172.000000         2391.935484  20.731579  \n",
              "...                   ...                 ...                 ...        ...  \n",
              "8641            48.266947           61.222706         1989.393458   9.775000  \n",
              "8642            48.024201           62.014360         1991.812205   4.140000  \n",
              "8643            48.283297           60.511903         1983.132701   7.700000  \n",
              "8644            47.817090           62.360699         2015.385052   8.014286  \n",
              "8645            47.996948           61.922495         1995.001809   8.700000  \n",
              "\n",
              "[8646 rows x 74 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4298ebad-5287-4bf0-96e8-c836ee741f87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGE</th>\n",
              "      <th>ALT</th>\n",
              "      <th>ART BP Systolic</th>\n",
              "      <th>ART BP mean</th>\n",
              "      <th>ART Lumen Volume</th>\n",
              "      <th>AST</th>\n",
              "      <th>Admission Weight (Kg)</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Alkaline Phosphate</th>\n",
              "      <th>Ammonia</th>\n",
              "      <th>...</th>\n",
              "      <th>Pulmonary Artery Pressure mean</th>\n",
              "      <th>RELIGION</th>\n",
              "      <th>Respiratory Rate</th>\n",
              "      <th>Sodium (serum)</th>\n",
              "      <th>Temperature Celsius</th>\n",
              "      <th>Total Bilirubin</th>\n",
              "      <th>Venous CO2 Pressure</th>\n",
              "      <th>Venous O2 Pressure</th>\n",
              "      <th>Ventilator Tank #1</th>\n",
              "      <th>WBC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.287671</td>\n",
              "      <td>14.625000</td>\n",
              "      <td>110.121564</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>1.776951</td>\n",
              "      <td>18.666667</td>\n",
              "      <td>65.284748</td>\n",
              "      <td>1.976923</td>\n",
              "      <td>67.937500</td>\n",
              "      <td>41.896000</td>\n",
              "      <td>...</td>\n",
              "      <td>28.120382</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>19.213248</td>\n",
              "      <td>135.831776</td>\n",
              "      <td>36.790870</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>61.875000</td>\n",
              "      <td>49.875000</td>\n",
              "      <td>2035.542169</td>\n",
              "      <td>10.573626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81.128767</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>115.156716</td>\n",
              "      <td>356.500000</td>\n",
              "      <td>1.227688</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>68.100000</td>\n",
              "      <td>3.350000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>-189.839353</td>\n",
              "      <td>...</td>\n",
              "      <td>-382.848191</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>16.885154</td>\n",
              "      <td>143.058824</td>\n",
              "      <td>36.490050</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>60.500000</td>\n",
              "      <td>40.750000</td>\n",
              "      <td>2156.250000</td>\n",
              "      <td>7.423077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>75.887671</td>\n",
              "      <td>20.666667</td>\n",
              "      <td>94.429669</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>106.187923</td>\n",
              "      <td>2.083333</td>\n",
              "      <td>146.833333</td>\n",
              "      <td>53.250487</td>\n",
              "      <td>...</td>\n",
              "      <td>29.688995</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>20.700000</td>\n",
              "      <td>140.016129</td>\n",
              "      <td>39.923196</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>49.166667</td>\n",
              "      <td>59.833333</td>\n",
              "      <td>1879.120879</td>\n",
              "      <td>14.581013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53.682192</td>\n",
              "      <td>30.333333</td>\n",
              "      <td>117.364350</td>\n",
              "      <td>95.863471</td>\n",
              "      <td>1.781689</td>\n",
              "      <td>38.250000</td>\n",
              "      <td>77.877338</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>44.048273</td>\n",
              "      <td>...</td>\n",
              "      <td>27.977587</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>18.500367</td>\n",
              "      <td>143.695652</td>\n",
              "      <td>37.378148</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>83.166667</td>\n",
              "      <td>79.666667</td>\n",
              "      <td>1954.705882</td>\n",
              "      <td>13.052500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>70.758904</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>129.543340</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>1.691685</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>60.389001</td>\n",
              "      <td>2.050000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>44.967481</td>\n",
              "      <td>...</td>\n",
              "      <td>30.031274</td>\n",
              "      <td>NOT SPECIFIED</td>\n",
              "      <td>19.098462</td>\n",
              "      <td>141.368421</td>\n",
              "      <td>36.629274</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>2391.935484</td>\n",
              "      <td>20.731579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8641</th>\n",
              "      <td>62.959449</td>\n",
              "      <td>301.757721</td>\n",
              "      <td>93.413793</td>\n",
              "      <td>86.177893</td>\n",
              "      <td>1.705318</td>\n",
              "      <td>148.690843</td>\n",
              "      <td>79.201246</td>\n",
              "      <td>2.761528</td>\n",
              "      <td>128.575455</td>\n",
              "      <td>47.687032</td>\n",
              "      <td>...</td>\n",
              "      <td>28.143650</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>35.796296</td>\n",
              "      <td>1.634226</td>\n",
              "      <td>48.266947</td>\n",
              "      <td>61.222706</td>\n",
              "      <td>1989.393458</td>\n",
              "      <td>9.775000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8642</th>\n",
              "      <td>72.651520</td>\n",
              "      <td>-55.682184</td>\n",
              "      <td>156.020408</td>\n",
              "      <td>88.023220</td>\n",
              "      <td>1.702226</td>\n",
              "      <td>176.864488</td>\n",
              "      <td>46.921161</td>\n",
              "      <td>2.902954</td>\n",
              "      <td>160.588884</td>\n",
              "      <td>47.762395</td>\n",
              "      <td>...</td>\n",
              "      <td>25.354754</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>17.406250</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>36.321637</td>\n",
              "      <td>1.800394</td>\n",
              "      <td>48.024201</td>\n",
              "      <td>62.014360</td>\n",
              "      <td>1991.812205</td>\n",
              "      <td>4.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8643</th>\n",
              "      <td>64.419431</td>\n",
              "      <td>257.347876</td>\n",
              "      <td>109.131148</td>\n",
              "      <td>88.171228</td>\n",
              "      <td>1.704027</td>\n",
              "      <td>189.495112</td>\n",
              "      <td>71.899354</td>\n",
              "      <td>2.641244</td>\n",
              "      <td>148.622771</td>\n",
              "      <td>47.687032</td>\n",
              "      <td>...</td>\n",
              "      <td>27.748658</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>16.372881</td>\n",
              "      <td>137.600000</td>\n",
              "      <td>37.399306</td>\n",
              "      <td>1.748749</td>\n",
              "      <td>48.283297</td>\n",
              "      <td>60.511903</td>\n",
              "      <td>1983.132701</td>\n",
              "      <td>7.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8644</th>\n",
              "      <td>56.803376</td>\n",
              "      <td>168.689049</td>\n",
              "      <td>106.333333</td>\n",
              "      <td>85.562593</td>\n",
              "      <td>1.715720</td>\n",
              "      <td>113.731382</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>2.893243</td>\n",
              "      <td>165.371832</td>\n",
              "      <td>46.691705</td>\n",
              "      <td>...</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>138.700000</td>\n",
              "      <td>36.129641</td>\n",
              "      <td>3.808259</td>\n",
              "      <td>47.817090</td>\n",
              "      <td>62.360699</td>\n",
              "      <td>2015.385052</td>\n",
              "      <td>8.014286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8645</th>\n",
              "      <td>58.191823</td>\n",
              "      <td>235.772172</td>\n",
              "      <td>119.978704</td>\n",
              "      <td>87.592234</td>\n",
              "      <td>1.705197</td>\n",
              "      <td>196.041651</td>\n",
              "      <td>83.828510</td>\n",
              "      <td>2.922918</td>\n",
              "      <td>148.342685</td>\n",
              "      <td>47.967151</td>\n",
              "      <td>...</td>\n",
              "      <td>27.779389</td>\n",
              "      <td>CATHOLIC</td>\n",
              "      <td>18.647409</td>\n",
              "      <td>137.888889</td>\n",
              "      <td>36.437222</td>\n",
              "      <td>1.772930</td>\n",
              "      <td>47.996948</td>\n",
              "      <td>61.922495</td>\n",
              "      <td>1995.001809</td>\n",
              "      <td>8.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8646 rows × 74 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4298ebad-5287-4bf0-96e8-c836ee741f87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4298ebad-5287-4bf0-96e8-c836ee741f87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4298ebad-5287-4bf0-96e8-c836ee741f87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbe = ce.CatBoostEncoder(cols=['RELIGION'])\n",
        "delirium_dataset_encoded['RELIGION'] = cbe.fit_transform(delirium_dataset['RELIGION'],delirium_dataset.Delirium)\n",
        "delirium_dataset_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "zjbXqq_hgqHU",
        "outputId": "a0988ec8-7fe2-4737-99ff-c937f7241511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            AGE         ALT  ART BP Systolic  ART BP mean  ART Lumen Volume  \\\n",
              "0     75.287671   14.625000       110.121564   117.000000          1.776951   \n",
              "1     81.128767   22.000000       115.156716   356.500000          1.227688   \n",
              "2     75.887671   20.666667        94.429669   125.000000          2.300000   \n",
              "3     53.682192   30.333333       117.364350    95.863471          1.781689   \n",
              "4     70.758904   71.000000       129.543340    85.000000          1.691685   \n",
              "...         ...         ...              ...          ...               ...   \n",
              "8641  62.959449  301.757721        93.413793    86.177893          1.705318   \n",
              "8642  72.651520  -55.682184       156.020408    88.023220          1.702226   \n",
              "8643  64.419431  257.347876       109.131148    88.171228          1.704027   \n",
              "8644  56.803376  168.689049       106.333333    85.562593          1.715720   \n",
              "8645  58.191823  235.772172       119.978704    87.592234          1.705197   \n",
              "\n",
              "             AST  Admission Weight (Kg)   Albumin  Alkaline Phosphate  \\\n",
              "0      18.666667              65.284748  1.976923           67.937500   \n",
              "1      30.000000              68.100000  3.350000           83.000000   \n",
              "2      18.500000             106.187923  2.083333          146.833333   \n",
              "3      38.250000              77.877338  3.000000           80.000000   \n",
              "4     113.000000              60.389001  2.050000          102.000000   \n",
              "...          ...                    ...       ...                 ...   \n",
              "8641  148.690843              79.201246  2.761528          128.575455   \n",
              "8642  176.864488              46.921161  2.902954          160.588884   \n",
              "8643  189.495112              71.899354  2.641244          148.622771   \n",
              "8644  113.731382              75.000000  2.893243          165.371832   \n",
              "8645  196.041651              83.828510  2.922918          148.342685   \n",
              "\n",
              "         Ammonia  ...  Pulmonary Artery Pressure mean  RELIGION  \\\n",
              "0      41.896000  ...                       28.120382  0.108721   \n",
              "1    -189.839353  ...                     -382.848191  0.108721   \n",
              "2      53.250487  ...                       29.688995  0.054360   \n",
              "3      44.048273  ...                       27.977587  0.054360   \n",
              "4      44.967481  ...                       30.031274  0.036240   \n",
              "...          ...  ...                             ...       ...   \n",
              "8641   47.687032  ...                       28.143650  0.117302   \n",
              "8642   47.762395  ...                       25.354754  0.117572   \n",
              "8643   47.687032  ...                       27.748658  0.117842   \n",
              "8644   46.691705  ...                       23.000000  0.117806   \n",
              "8645   47.967151  ...                       27.779389  0.117770   \n",
              "\n",
              "      Respiratory Rate  Sodium (serum)  Temperature Celsius  Total Bilirubin  \\\n",
              "0            19.213248      135.831776            36.790870         0.250000   \n",
              "1            16.885154      143.058824            36.490050         0.200000   \n",
              "2            20.700000      140.016129            39.923196         0.200000   \n",
              "3            18.500367      143.695652            37.378148         0.275000   \n",
              "4            19.098462      141.368421            36.629274         0.300000   \n",
              "...                ...             ...                  ...              ...   \n",
              "8641         22.900000      138.000000            35.796296         1.634226   \n",
              "8642         17.406250      135.000000            36.321637         1.800394   \n",
              "8643         16.372881      137.600000            37.399306         1.748749   \n",
              "8644         14.500000      138.700000            36.129641         3.808259   \n",
              "8645         18.647409      137.888889            36.437222         1.772930   \n",
              "\n",
              "      Venous CO2 Pressure  Venous O2 Pressure  Ventilator Tank #1        WBC  \n",
              "0               61.875000           49.875000         2035.542169  10.573626  \n",
              "1               60.500000           40.750000         2156.250000   7.423077  \n",
              "2               49.166667           59.833333         1879.120879  14.581013  \n",
              "3               83.166667           79.666667         1954.705882  13.052500  \n",
              "4               54.000000          172.000000         2391.935484  20.731579  \n",
              "...                   ...                 ...                 ...        ...  \n",
              "8641            48.266947           61.222706         1989.393458   9.775000  \n",
              "8642            48.024201           62.014360         1991.812205   4.140000  \n",
              "8643            48.283297           60.511903         1983.132701   7.700000  \n",
              "8644            47.817090           62.360699         2015.385052   8.014286  \n",
              "8645            47.996948           61.922495         1995.001809   8.700000  \n",
              "\n",
              "[8646 rows x 74 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e203630-6e54-44b0-80f2-e0399e6ba2be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGE</th>\n",
              "      <th>ALT</th>\n",
              "      <th>ART BP Systolic</th>\n",
              "      <th>ART BP mean</th>\n",
              "      <th>ART Lumen Volume</th>\n",
              "      <th>AST</th>\n",
              "      <th>Admission Weight (Kg)</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Alkaline Phosphate</th>\n",
              "      <th>Ammonia</th>\n",
              "      <th>...</th>\n",
              "      <th>Pulmonary Artery Pressure mean</th>\n",
              "      <th>RELIGION</th>\n",
              "      <th>Respiratory Rate</th>\n",
              "      <th>Sodium (serum)</th>\n",
              "      <th>Temperature Celsius</th>\n",
              "      <th>Total Bilirubin</th>\n",
              "      <th>Venous CO2 Pressure</th>\n",
              "      <th>Venous O2 Pressure</th>\n",
              "      <th>Ventilator Tank #1</th>\n",
              "      <th>WBC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.287671</td>\n",
              "      <td>14.625000</td>\n",
              "      <td>110.121564</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>1.776951</td>\n",
              "      <td>18.666667</td>\n",
              "      <td>65.284748</td>\n",
              "      <td>1.976923</td>\n",
              "      <td>67.937500</td>\n",
              "      <td>41.896000</td>\n",
              "      <td>...</td>\n",
              "      <td>28.120382</td>\n",
              "      <td>0.108721</td>\n",
              "      <td>19.213248</td>\n",
              "      <td>135.831776</td>\n",
              "      <td>36.790870</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>61.875000</td>\n",
              "      <td>49.875000</td>\n",
              "      <td>2035.542169</td>\n",
              "      <td>10.573626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81.128767</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>115.156716</td>\n",
              "      <td>356.500000</td>\n",
              "      <td>1.227688</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>68.100000</td>\n",
              "      <td>3.350000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>-189.839353</td>\n",
              "      <td>...</td>\n",
              "      <td>-382.848191</td>\n",
              "      <td>0.108721</td>\n",
              "      <td>16.885154</td>\n",
              "      <td>143.058824</td>\n",
              "      <td>36.490050</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>60.500000</td>\n",
              "      <td>40.750000</td>\n",
              "      <td>2156.250000</td>\n",
              "      <td>7.423077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>75.887671</td>\n",
              "      <td>20.666667</td>\n",
              "      <td>94.429669</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>106.187923</td>\n",
              "      <td>2.083333</td>\n",
              "      <td>146.833333</td>\n",
              "      <td>53.250487</td>\n",
              "      <td>...</td>\n",
              "      <td>29.688995</td>\n",
              "      <td>0.054360</td>\n",
              "      <td>20.700000</td>\n",
              "      <td>140.016129</td>\n",
              "      <td>39.923196</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>49.166667</td>\n",
              "      <td>59.833333</td>\n",
              "      <td>1879.120879</td>\n",
              "      <td>14.581013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53.682192</td>\n",
              "      <td>30.333333</td>\n",
              "      <td>117.364350</td>\n",
              "      <td>95.863471</td>\n",
              "      <td>1.781689</td>\n",
              "      <td>38.250000</td>\n",
              "      <td>77.877338</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>44.048273</td>\n",
              "      <td>...</td>\n",
              "      <td>27.977587</td>\n",
              "      <td>0.054360</td>\n",
              "      <td>18.500367</td>\n",
              "      <td>143.695652</td>\n",
              "      <td>37.378148</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>83.166667</td>\n",
              "      <td>79.666667</td>\n",
              "      <td>1954.705882</td>\n",
              "      <td>13.052500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>70.758904</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>129.543340</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>1.691685</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>60.389001</td>\n",
              "      <td>2.050000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>44.967481</td>\n",
              "      <td>...</td>\n",
              "      <td>30.031274</td>\n",
              "      <td>0.036240</td>\n",
              "      <td>19.098462</td>\n",
              "      <td>141.368421</td>\n",
              "      <td>36.629274</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>2391.935484</td>\n",
              "      <td>20.731579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8641</th>\n",
              "      <td>62.959449</td>\n",
              "      <td>301.757721</td>\n",
              "      <td>93.413793</td>\n",
              "      <td>86.177893</td>\n",
              "      <td>1.705318</td>\n",
              "      <td>148.690843</td>\n",
              "      <td>79.201246</td>\n",
              "      <td>2.761528</td>\n",
              "      <td>128.575455</td>\n",
              "      <td>47.687032</td>\n",
              "      <td>...</td>\n",
              "      <td>28.143650</td>\n",
              "      <td>0.117302</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>35.796296</td>\n",
              "      <td>1.634226</td>\n",
              "      <td>48.266947</td>\n",
              "      <td>61.222706</td>\n",
              "      <td>1989.393458</td>\n",
              "      <td>9.775000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8642</th>\n",
              "      <td>72.651520</td>\n",
              "      <td>-55.682184</td>\n",
              "      <td>156.020408</td>\n",
              "      <td>88.023220</td>\n",
              "      <td>1.702226</td>\n",
              "      <td>176.864488</td>\n",
              "      <td>46.921161</td>\n",
              "      <td>2.902954</td>\n",
              "      <td>160.588884</td>\n",
              "      <td>47.762395</td>\n",
              "      <td>...</td>\n",
              "      <td>25.354754</td>\n",
              "      <td>0.117572</td>\n",
              "      <td>17.406250</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>36.321637</td>\n",
              "      <td>1.800394</td>\n",
              "      <td>48.024201</td>\n",
              "      <td>62.014360</td>\n",
              "      <td>1991.812205</td>\n",
              "      <td>4.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8643</th>\n",
              "      <td>64.419431</td>\n",
              "      <td>257.347876</td>\n",
              "      <td>109.131148</td>\n",
              "      <td>88.171228</td>\n",
              "      <td>1.704027</td>\n",
              "      <td>189.495112</td>\n",
              "      <td>71.899354</td>\n",
              "      <td>2.641244</td>\n",
              "      <td>148.622771</td>\n",
              "      <td>47.687032</td>\n",
              "      <td>...</td>\n",
              "      <td>27.748658</td>\n",
              "      <td>0.117842</td>\n",
              "      <td>16.372881</td>\n",
              "      <td>137.600000</td>\n",
              "      <td>37.399306</td>\n",
              "      <td>1.748749</td>\n",
              "      <td>48.283297</td>\n",
              "      <td>60.511903</td>\n",
              "      <td>1983.132701</td>\n",
              "      <td>7.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8644</th>\n",
              "      <td>56.803376</td>\n",
              "      <td>168.689049</td>\n",
              "      <td>106.333333</td>\n",
              "      <td>85.562593</td>\n",
              "      <td>1.715720</td>\n",
              "      <td>113.731382</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>2.893243</td>\n",
              "      <td>165.371832</td>\n",
              "      <td>46.691705</td>\n",
              "      <td>...</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.117806</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>138.700000</td>\n",
              "      <td>36.129641</td>\n",
              "      <td>3.808259</td>\n",
              "      <td>47.817090</td>\n",
              "      <td>62.360699</td>\n",
              "      <td>2015.385052</td>\n",
              "      <td>8.014286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8645</th>\n",
              "      <td>58.191823</td>\n",
              "      <td>235.772172</td>\n",
              "      <td>119.978704</td>\n",
              "      <td>87.592234</td>\n",
              "      <td>1.705197</td>\n",
              "      <td>196.041651</td>\n",
              "      <td>83.828510</td>\n",
              "      <td>2.922918</td>\n",
              "      <td>148.342685</td>\n",
              "      <td>47.967151</td>\n",
              "      <td>...</td>\n",
              "      <td>27.779389</td>\n",
              "      <td>0.117770</td>\n",
              "      <td>18.647409</td>\n",
              "      <td>137.888889</td>\n",
              "      <td>36.437222</td>\n",
              "      <td>1.772930</td>\n",
              "      <td>47.996948</td>\n",
              "      <td>61.922495</td>\n",
              "      <td>1995.001809</td>\n",
              "      <td>8.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8646 rows × 74 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e203630-6e54-44b0-80f2-e0399e6ba2be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e203630-6e54-44b0-80f2-e0399e6ba2be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e203630-6e54-44b0-80f2-e0399e6ba2be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "delirium_dataset_encoded.to_csv(\"delirium_dataset_catboost_encoded.csv\")"
      ],
      "metadata": {
        "id": "9jj_0iuagUds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disloc=np.unique(delirium_dataset['DISCHARGE_LOCATION'].tolist())\n",
        "eth=np.unique(delirium_dataset['ETHNICITY'].tolist())\n",
        "ins=np.unique(delirium_dataset['INSURANCE'].tolist())\n",
        "lang=np.unique(delirium_dataset['LANGUAGE'].tolist())\n",
        "martst=np.unique(delirium_dataset['MARITAL_STATUS'].tolist())\n",
        "rel=np.unique(delirium_dataset['RELIGION'].tolist())"
      ],
      "metadata": {
        "id": "uTTFDt0wagF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(lang))\n",
        "print(len(rel))\n",
        "print(len(disloc))\n",
        "print(len(eth))\n",
        "print(len(martst))\n",
        "print(len(ins))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojo0wUPsai00",
        "outputId": "e3a9c448-c8fe-46b9-fe39-f92a3c6e7a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n",
            "16\n",
            "14\n",
            "13\n",
            "7\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBBOOST Hyperparameters Tuning"
      ],
      "metadata": {
        "id": "SnvRR3Zme35s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imbalanced Dataset "
      ],
      "metadata": {
        "id": "GHdY6xxc-A-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = delirium_dataset_encoded[\"Delirium\"].values\n",
        "X=delirium_dataset_encoded.drop([\"Delirium\"], axis=1)\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.30, random_state=0)\n"
      ],
      "metadata": {
        "id": "86Vic8kh-D3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Undersampled Dataset"
      ],
      "metadata": {
        "id": "lvy1Uwo0-Fxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample=delirium_dataset_encoded[delirium_dataset_encoded['Delirium']==0]\n",
        "delirium=delirium_dataset_encoded[delirium_dataset_encoded['Delirium']==1]"
      ],
      "metadata": {
        "id": "Fr1gr5Au-I7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_me, sample = train_test_split(sample, test_size = 0.1)"
      ],
      "metadata": {
        "id": "B-y94-MY-dpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "sample = pd.concat([sample, delirium])\n",
        "\n",
        "# Split into train and test units.\n",
        "xtrain, xtest = train_test_split(sample, test_size = 0.3)\n",
        "ytrain = xtrain['Delirium']\n",
        "ytest = xtest['Delirium']\n",
        "xtrain.drop('Delirium', 1, inplace = True)\n",
        "xtest.drop('Delirium', 1, inplace = True)"
      ],
      "metadata": {
        "id": "qRx3fq4I-oWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Oversampled Dataset"
      ],
      "metadata": {
        "id": "BSO8RUjs-JSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imblearn"
      ],
      "metadata": {
        "id": "emSW2igr_sbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE \n",
        "sm = SMOTE(random_state=42,sampling_strategy={1:7000})\n",
        "X_res, y_res = sm.fit_resample(X, y)\n",
        "print('Resampled dataset shape {}'.format(Counter(y_res)))\n",
        "'''Split the resampled data into train & test data with 70:30 mix'''\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(X_res, y_res, test_size=0.30, random_state=0)\n",
        "print('xtrain shape')\n",
        "print(xtrain.shape)\n",
        "print('xtest shape')\n",
        "print(xtest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_06cmog-L6E",
        "outputId": "884b83ed-fb09-481a-ed96-8d78cf611c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampled dataset shape Counter({0: 7706, 1: 7000})\n",
            "xtrain shape\n",
            "(10294, 73)\n",
            "xtest shape\n",
            "(4412, 73)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters Tuning"
      ],
      "metadata": {
        "id": "v0lApHev-Mmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize'] = 12, 4"
      ],
      "metadata": {
        "id": "d-m6VbuZiC5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y = delirium_dataset_encoded[\"Delirium\"].values\n",
        "#X=delirium_dataset_encoded.drop([\"Delirium\"], axis=1)\n",
        "X_t, test, y_t, testY = train_test_split(X_res, y_res, test_size=0.2, random_state=0)\n",
        "train, valid, trainY, validY = train_test_split(X_t, y_t, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "ivfs3mdAiQtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "dtrain = xgb.DMatrix(train, label=trainY)\n",
        "dvalid = xgb.DMatrix(valid, label=validY)\n",
        "dtest = xgb.DMatrix(test, label=testY)\n",
        "\n",
        "## fixed parameters\n",
        "num_rounds=20 # number of boosting iterations\n",
        "\n",
        "param = {'silent':1,\n",
        "         'min_child_weight':1,\n",
        "         'objective':'binary:logistic',\n",
        "         'eval_metric':'auc',\n",
        "         'seed' : 1234}  "
      ],
      "metadata": {
        "id": "MzDt2C5GimrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "ratio_neg_to_pos = sum(trainY==0)/sum(trainY==1)  ## = 608\n",
        "print('Ratio of negative to positive instances: {:6.1f}'.format(ratio_neg_to_pos))\n",
        "\n",
        "## parameters to be tuned\n",
        "tune_dic = OrderedDict()\n",
        "\n",
        "tune_dic['max_depth']= [5,10,15,20,25] ## maximum tree depth\n",
        "tune_dic[\"min_child_weight\"]= [ 1, 3, 5, 7 ]\n",
        "tune_dic[\"learning_rate\"]=[0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] \n",
        "tune_dic['subsample']=[0.5,0.6,0.7,0.8,0.9,1.0] ## proportion of training instances used in trees\n",
        "tune_dic['colsample_bytree']= [0.5,0.6,0.7,0.8,0.9,1.0] ## subsample ratio of columns\n",
        "tune_dic['eta']= [0.01,0.05,0.10,0.20,0.30,0.40]  ## learning rate\n",
        "tune_dic['gamma']= [0.00,0.05,0.10,0.15,0.20]  ## minimum loss function reduction required for a split\n",
        "tune_dic['scale_pos_weight']=[30,40,50,300,400,500,600,700] ## relative weight of positive/negative instances\n",
        "\n",
        "lengths = [len(lst) for lst in tune_dic.values()]\n",
        "\n",
        "combs=1\n",
        "for i in range(len(lengths)):\n",
        "    combs *= lengths[i]\n",
        "print('Total number of combinations: {:16d}'.format(combs))  \n",
        "\n",
        "maxiter=100\n",
        "\n",
        "columns=[*tune_dic.keys()]+['F-Score','Best F-Score']\n",
        "results = pd.DataFrame(index=range(maxiter), columns=columns) ## dataframe to hold training results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUgYXrNjimoE",
        "outputId": "c8bca701-e07c-4481-b692-51b4fa8289fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratio of negative to positive instances:    1.1\n",
            "Total number of combinations:            43200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perf_measures(preds, labels, print_conf_matrix=False):\n",
        "    \n",
        "    act_pos=sum(labels==1) ## actual positive\n",
        "    act_neg=len(labels) - act_pos ## actual negative\n",
        "    \n",
        "    pred_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5)) ## predicted positive\n",
        "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1)) ## predicted negative\n",
        "    \n",
        "    false_pos=pred_pos - true_pos ## false positive\n",
        "    false_neg=act_pos-true_pos ## false negative\n",
        "    true_neg=act_neg-false_pos ## true negative\n",
        "      \n",
        "    precision = true_pos/pred_pos ## tp/(tp+fp) percentage of correctly classified predicted positives\n",
        "    recall = true_pos/act_pos ## tp/(tp+fn) percentage of positives correctly classified\n",
        "    \n",
        "    f_score = 2*precision*recall/(precision+recall) \n",
        "    \n",
        "    if print_conf_matrix:\n",
        "        print('\\nconfusion matrix')\n",
        "        print('----------------')\n",
        "        print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
        "        print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
        "    \n",
        "    return(f_score)\n",
        "\n",
        "\n",
        "def do_train(cur_choice, param, train,train_s,trainY,valid,valid_s,validY,print_conf_matrix=False):\n",
        "    ## train with given fixed and variable parameters\n",
        "    ## and report the F-score on the validation dataset\n",
        "    \n",
        "    print('Parameters:')\n",
        "    for (key,value) in cur_choice.items():\n",
        "        print(key,': ',value,' ',end='')\n",
        "        param[key]=value\n",
        "    print('\\n')    \n",
        "    \n",
        "##    the commented-out segment below uses a watchlist to monitor the progress of the boosting iterations \n",
        "##    evallist  = [(train,train_s), (valid,valid_s)]\n",
        "##    model = xgb.train( param, train, num_boost_round=num_rounds,\n",
        "##                      evals=evallist,verbose_eval=False)  \n",
        "    \n",
        "    model = xgb.train( param, train, num_boost_round=num_rounds)  \n",
        "    \n",
        "    preds = model.predict(valid)\n",
        "    labels = valid.get_label()\n",
        "      \n",
        "    f_score = perf_measures(preds, labels,print_conf_matrix)\n",
        "    \n",
        "    return(f_score, model)    "
      ],
      "metadata": {
        "id": "h7SLj1-Rlp4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def next_choice(cur_params=None):\n",
        "    ## returns a random combination of the variable parameters (if cur_params=None)\n",
        "    ## or a random neighboring combination from cur_params\n",
        "    if cur_params:\n",
        "        ## chose parameter to change\n",
        "        ## parameter name and current value\n",
        "        choose_param_name, cur_value = random.choice(list(cur_choice.items())) ## parameter name \n",
        "       \n",
        "        all_values =  list(tune_dic[choose_param_name]) ## all values of selected parameter\n",
        "        cur_index = all_values.index(cur_value) ## current index of selected parameter\n",
        "        \n",
        "        if cur_index==0: ## if it is the first in the range select the second one\n",
        "            next_index=1\n",
        "        elif cur_index==len(all_values)-1: ## if it is the last in the range select the previous one\n",
        "            next_index=len(all_values)-2\n",
        "        else: ## otherwise select the left or right value randomly\n",
        "            direction=np.random.choice([-1,1])\n",
        "            next_index=cur_index + direction\n",
        "\n",
        "        next_params = dict((k,v) for k,v in cur_params.items())\n",
        "        next_params[choose_param_name] = all_values[next_index] ## change the value of the selected parameter\n",
        "        print('selected move: {:10s}: from {:6.2f} to {:6.2f}'.\n",
        "              format(choose_param_name, cur_value, all_values[next_index] ))\n",
        "    else: ## generate a random combination of parameters\n",
        "        next_params=dict()\n",
        "        for i in range(len(tune_dic)):\n",
        "            key = [*tune_dic.keys()][i] \n",
        "            values = [*tune_dic.values()][i]\n",
        "            next_params[key] = np.random.choice(values)\n",
        "    return(next_params)  "
      ],
      "metadata": {
        "id": "3xUO8XiKlp09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "t0 = time.clock()\n",
        "\n",
        "T=0.40\n",
        "best_params = dict() ## initialize dictionary to hold the best parameters\n",
        "\n",
        "best_f_score = -1. ## initialize best f-score\n",
        "prev_f_score = -1. ## initialize previous f-score\n",
        "prev_choice = None ## initialize previous selection of parameters\n",
        "weights = list(map(lambda x: 10**x, [0,1,2,3,4])) ## weights for the hash function\n",
        "hash_values=set()\n",
        "\n",
        "for iter in range(maxiter):\n",
        "    print('\\nIteration = {:5d}  T = {:12.6f}'.format(iter,T))\n",
        "\n",
        "    ## find next selection of parameters not visited before\n",
        "    while True:\n",
        "        cur_choice=next_choice(prev_choice) ## first selection or selection-neighbor of prev_choice\n",
        "         \n",
        "        ## indices of the selections in alphabetical order of the parameters    \n",
        "        indices=[tune_dic[name].index(cur_choice[name]) for name in sorted([*tune_dic.keys()])]\n",
        "        \n",
        "        ## check if selection has already been visited\n",
        "        hash_val = sum([i*j for (i, j) in zip(weights, indices)])\n",
        "        if hash_val in hash_values:\n",
        "            print('\\nCombination revisited - searching again')\n",
        "\n",
        "#        tmp=abs(results.loc[:,[*cur_choice.keys()]] - list(cur_choice.values()))\n",
        "#        tmp=tmp.sum(axis=1)\n",
        "#        if any(tmp==0): ## selection has already been visited\n",
        "#            print('\\nCombination revisited - searching again')\n",
        "        else:\n",
        "            hash_values.add(hash_val)\n",
        "            break ## break out of the while-loop\n",
        "    \n",
        "    \n",
        "    ## train the model and obtain f-score on the validation dataset\n",
        "    f_score,model=do_train(cur_choice, param, dtrain,'train',trainY,dvalid,'valid',validY)\n",
        "    \n",
        "    ## store the parameters\n",
        "    results.loc[iter,[*cur_choice.keys()]]=list(cur_choice.values())\n",
        "    \n",
        "    print('    F-Score: {:6.2f}  previous: {:6.2f}  best so far: {:6.2f}'.format(f_score, prev_f_score, best_f_score))\n",
        " \n",
        "    if f_score > prev_f_score:\n",
        "        print('    Local improvement')\n",
        "        \n",
        "        ## accept this combination as the new starting point\n",
        "        prev_f_score = f_score\n",
        "        prev_choice = cur_choice\n",
        "        \n",
        "        ## update best parameters if the f-score is globally better\n",
        "        if f_score > best_f_score:\n",
        "            \n",
        "            best_f_score = f_score\n",
        "            print('    Global improvement - best f-score updated')\n",
        "            for (key,value) in prev_choice.items():\n",
        "                best_params[key]=value\n",
        "\n",
        "    else: ## f-score is smaller than the previous one\n",
        "        \n",
        "        ## accept this combination as the new starting point with probability exp(-(1.6 x f-score decline)/temperature) \n",
        "        rnd = random.random()\n",
        "        diff = f_score-prev_f_score\n",
        "        thres=np.exp(1.3*diff/T)\n",
        "        if rnd <= thres:\n",
        "            print('    Worse result. F-Score change: {:8.4f}  threshold: {:6.4f}  random number: {:6.4f} -> accepted'.\n",
        "                  format(diff, thres, rnd))\n",
        "            prev_f_score = f_score\n",
        "            prev_choice = cur_choice\n",
        " \n",
        "        else:\n",
        "            ## do not update previous f-score and previous choice\n",
        "            print('    Worse result. F-Score change: {:8.4f}  threshold: {:6.4f}  random number: {:6.4f} -> rejected'.\n",
        "                 format(diff, thres, rnd))\n",
        "    ## store results\n",
        "    results.loc[iter,'F-Score']=f_score\n",
        "    results.loc[iter,'Best F-Score']=best_f_score\n",
        "    if iter % 5 == 0: T=0.85*T  ## reduce temperature every 5 iterations and continue \n",
        "        \n",
        "print('\\n{:6.1f} minutes process time\\n'.format((time.clock() - t0)/60))    \n",
        "\n",
        "print('Best variable parameters found:\\n')\n",
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdOXo76dlpx7",
        "outputId": "38feb516-13f1-4e01-9455-631a03e5f8db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration =     0  T =     0.400000\n",
            "Parameters:\n",
            "max_depth :  10  subsample :  0.9  colsample_bytree :  1.0  eta :  0.4  gamma :  0.15  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.85  previous:  -1.00  best so far:  -1.00\n",
            "    Local improvement\n",
            "    Global improvement - best f-score updated\n",
            "\n",
            "Iteration =     1  T =     0.340000\n",
            "selected move: colsample_bytree: from   1.00 to   0.90\n",
            "Parameters:\n",
            "max_depth :  10  subsample :  0.9  colsample_bytree :  0.9  eta :  0.4  gamma :  0.15  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.85  previous:   0.85  best so far:   0.85\n",
            "    Local improvement\n",
            "    Global improvement - best f-score updated\n",
            "\n",
            "Iteration =     2  T =     0.340000\n",
            "selected move: colsample_bytree: from   0.90 to   0.80\n",
            "Parameters:\n",
            "max_depth :  10  subsample :  0.9  colsample_bytree :  0.8  eta :  0.4  gamma :  0.15  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.84  previous:   0.85  best so far:   0.85\n",
            "    Worse result. F-Score change:  -0.0059  threshold: 0.9776  random number: 0.3005 -> accepted\n",
            "\n",
            "Iteration =     3  T =     0.340000\n",
            "selected move: eta       : from   0.40 to   0.30\n",
            "Parameters:\n",
            "max_depth :  10  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  gamma :  0.15  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.82  previous:   0.84  best so far:   0.85\n",
            "    Worse result. F-Score change:  -0.0215  threshold: 0.9210  random number: 0.5620 -> accepted\n",
            "\n",
            "Iteration =     4  T =     0.340000\n",
            "selected move: gamma     : from   0.15 to   0.10\n",
            "Parameters:\n",
            "max_depth :  10  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  gamma :  0.1  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.82  previous:   0.82  best so far:   0.85\n",
            "    Local improvement\n",
            "\n",
            "Iteration =     5  T =     0.340000\n",
            "selected move: gamma     : from   0.10 to   0.15\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: max_depth : from  10.00 to  15.00\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  gamma :  0.1  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.86  previous:   0.82  best so far:   0.85\n",
            "    Local improvement\n",
            "    Global improvement - best f-score updated\n",
            "\n",
            "Iteration =     6  T =     0.289000\n",
            "selected move: eta       : from   0.30 to   0.40\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.8  eta :  0.4  gamma :  0.1  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.86  previous:   0.86  best so far:   0.86\n",
            "    Local improvement\n",
            "    Global improvement - best f-score updated\n",
            "\n",
            "Iteration =     7  T =     0.289000\n",
            "selected move: eta       : from   0.40 to   0.30\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: max_depth : from  15.00 to  20.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.4  gamma :  0.1  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.86  best so far:   0.86\n",
            "    Local improvement\n",
            "    Global improvement - best f-score updated\n",
            "\n",
            "Iteration =     8  T =     0.289000\n",
            "selected move: eta       : from   0.40 to   0.30\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  gamma :  0.1  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.88  best so far:   0.88\n",
            "    Worse result. F-Score change:  -0.0140  threshold: 0.9392  random number: 0.0035 -> accepted\n",
            "\n",
            "Iteration =     9  T =     0.289000\n",
            "selected move: gamma     : from   0.10 to   0.15\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  gamma :  0.15  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.87  best so far:   0.88\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    10  T =     0.289000\n",
            "selected move: scale_pos_weight: from  50.00 to  40.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  gamma :  0.15  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.88  best so far:   0.88\n",
            "    Worse result. F-Score change:  -0.0012  threshold: 0.9946  random number: 0.8954 -> accepted\n",
            "\n",
            "Iteration =    11  T =     0.245650\n",
            "selected move: max_depth : from  20.00 to  25.00\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  gamma :  0.15  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.88  best so far:   0.88\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    12  T =     0.245650\n",
            "selected move: eta       : from   0.30 to   0.40\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.8  eta :  0.4  gamma :  0.15  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.88  best so far:   0.88\n",
            "    Local improvement\n",
            "    Global improvement - best f-score updated\n",
            "\n",
            "Iteration =    13  T =     0.245650\n",
            "selected move: subsample : from   0.90 to   0.80\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: gamma     : from   0.15 to   0.10\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.8  eta :  0.4  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0027  threshold: 0.9860  random number: 0.0116 -> accepted\n",
            "\n",
            "Iteration =    14  T =     0.245650\n",
            "selected move: colsample_bytree: from   0.80 to   0.70\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0091  threshold: 0.9532  random number: 0.7213 -> accepted\n",
            "\n",
            "Iteration =    15  T =     0.245650\n",
            "selected move: max_depth : from  25.00 to  20.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.88  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    16  T =     0.208803\n",
            "selected move: colsample_bytree: from   0.70 to   0.80\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.4  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.88  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    17  T =     0.208803\n",
            "selected move: subsample : from   0.90 to   1.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: scale_pos_weight: from  40.00 to  30.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.4  gamma :  0.1  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.88  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    18  T =     0.208803\n",
            "selected move: eta       : from   0.40 to   0.30\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  gamma :  0.1  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0062  threshold: 0.9619  random number: 0.2301 -> accepted\n",
            "\n",
            "Iteration =    19  T =     0.208803\n",
            "selected move: subsample : from   0.90 to   1.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: subsample : from   1.00 to   0.90\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: colsample_bytree: from   0.80 to   0.70\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.3  gamma :  0.1  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.88  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    20  T =     0.208803\n",
            "selected move: gamma     : from   0.10 to   0.05\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.3  gamma :  0.05  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.89  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    21  T =     0.177482\n",
            "selected move: colsample_bytree: from   0.70 to   0.60\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.3  gamma :  0.05  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.89  best so far:   0.89\n",
            "    Local improvement\n",
            "    Global improvement - best f-score updated\n",
            "\n",
            "Iteration =    22  T =     0.177482\n",
            "selected move: gamma     : from   0.05 to   0.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.3  gamma :  0.0  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.89  best so far:   0.89\n",
            "    Local improvement\n",
            "    Global improvement - best f-score updated\n",
            "\n",
            "Iteration =    23  T =     0.177482\n",
            "selected move: subsample : from   0.90 to   1.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: scale_pos_weight: from  30.00 to  40.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.3  gamma :  0.0  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0215  threshold: 0.8545  random number: 0.1838 -> accepted\n",
            "\n",
            "Iteration =    24  T =     0.177482\n",
            "selected move: scale_pos_weight: from  40.00 to  50.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.3  gamma :  0.0  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.87  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    25  T =     0.177482\n",
            "selected move: gamma     : from   0.00 to   0.05\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.3  gamma :  0.05  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.87  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0021  threshold: 0.9846  random number: 0.9288 -> accepted\n",
            "\n",
            "Iteration =    26  T =     0.150860\n",
            "selected move: colsample_bytree: from   0.60 to   0.70\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.3  gamma :  0.05  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.87  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    27  T =     0.150860\n",
            "selected move: scale_pos_weight: from  50.00 to  40.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.3  gamma :  0.05  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.87  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    28  T =     0.150860\n",
            "selected move: eta       : from   0.30 to   0.40\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.05  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.87  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    29  T =     0.150860\n",
            "selected move: gamma     : from   0.05 to   0.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.0  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0054  threshold: 0.9547  random number: 0.2120 -> accepted\n",
            "\n",
            "Iteration =    30  T =     0.150860\n",
            "selected move: scale_pos_weight: from  40.00 to  50.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.0  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.88  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    31  T =     0.128231\n",
            "selected move: scale_pos_weight: from  50.00 to 300.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.0  scale_pos_weight :  300  \n",
            "\n",
            "    F-Score:   0.83  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0558  threshold: 0.5680  random number: 0.2514 -> accepted\n",
            "\n",
            "Iteration =    32  T =     0.128231\n",
            "selected move: colsample_bytree: from   0.70 to   0.60\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.4  gamma :  0.0  scale_pos_weight :  300  \n",
            "\n",
            "    F-Score:   0.83  previous:   0.83  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0010  threshold: 0.9903  random number: 0.9852 -> accepted\n",
            "\n",
            "Iteration =    33  T =     0.128231\n",
            "selected move: subsample : from   0.90 to   0.80\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: max_depth : from  20.00 to  15.00\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.6  eta :  0.4  gamma :  0.0  scale_pos_weight :  300  \n",
            "\n",
            "    F-Score:   0.81  previous:   0.83  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0167  threshold: 0.8439  random number: 0.5863 -> accepted\n",
            "\n",
            "Iteration =    34  T =     0.128231\n",
            "selected move: scale_pos_weight: from 300.00 to 400.00\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.6  eta :  0.4  gamma :  0.0  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.81  previous:   0.81  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0032  threshold: 0.9684  random number: 0.7182 -> accepted\n",
            "\n",
            "Iteration =    35  T =     0.128231\n",
            "selected move: gamma     : from   0.00 to   0.05\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.6  eta :  0.4  gamma :  0.05  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.81  previous:   0.81  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    36  T =     0.108996\n",
            "selected move: eta       : from   0.40 to   0.30\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.6  eta :  0.3  gamma :  0.05  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.78  previous:   0.81  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0366  threshold: 0.6461  random number: 0.0508 -> accepted\n",
            "\n",
            "Iteration =    37  T =     0.108996\n",
            "selected move: scale_pos_weight: from 400.00 to 500.00\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.6  eta :  0.3  gamma :  0.05  scale_pos_weight :  500  \n",
            "\n",
            "    F-Score:   0.78  previous:   0.78  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    38  T =     0.108996\n",
            "selected move: scale_pos_weight: from 500.00 to 400.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: eta       : from   0.30 to   0.20\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.6  eta :  0.2  gamma :  0.05  scale_pos_weight :  500  \n",
            "\n",
            "    F-Score:   0.70  previous:   0.78  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0754  threshold: 0.4067  random number: 0.7856 -> rejected\n",
            "\n",
            "Iteration =    39  T =     0.108996\n",
            "selected move: colsample_bytree: from   0.60 to   0.70\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.7  eta :  0.3  gamma :  0.05  scale_pos_weight :  500  \n",
            "\n",
            "    F-Score:   0.77  previous:   0.78  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0069  threshold: 0.9208  random number: 0.1522 -> accepted\n",
            "\n",
            "Iteration =    40  T =     0.108996\n",
            "selected move: scale_pos_weight: from 500.00 to 400.00\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.7  eta :  0.3  gamma :  0.05  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.78  previous:   0.77  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    41  T =     0.092647\n",
            "selected move: gamma     : from   0.05 to   0.10\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.7  eta :  0.3  gamma :  0.1  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.78  previous:   0.78  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    42  T =     0.092647\n",
            "selected move: eta       : from   0.30 to   0.20\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.7  eta :  0.2  gamma :  0.1  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.72  previous:   0.78  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0664  threshold: 0.3938  random number: 0.1673 -> accepted\n",
            "\n",
            "Iteration =    43  T =     0.092647\n",
            "selected move: gamma     : from   0.10 to   0.15\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.7  eta :  0.2  gamma :  0.15  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.72  previous:   0.72  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    44  T =     0.092647\n",
            "selected move: colsample_bytree: from   0.70 to   0.80\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.8  eta :  0.2  gamma :  0.15  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.71  previous:   0.72  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0100  threshold: 0.8688  random number: 0.4671 -> accepted\n",
            "\n",
            "Iteration =    45  T =     0.092647\n",
            "selected move: colsample_bytree: from   0.80 to   0.90\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.9  eta :  0.2  gamma :  0.15  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.71  previous:   0.71  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    46  T =     0.078750\n",
            "selected move: gamma     : from   0.15 to   0.10\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.9  eta :  0.2  gamma :  0.1  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.71  previous:   0.71  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    47  T =     0.078750\n",
            "selected move: colsample_bytree: from   0.90 to   1.00\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  1.0  eta :  0.2  gamma :  0.1  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.71  previous:   0.71  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0017  threshold: 0.9724  random number: 0.1133 -> accepted\n",
            "\n",
            "Iteration =    48  T =     0.078750\n",
            "selected move: gamma     : from   0.10 to   0.05\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  1.0  eta :  0.2  gamma :  0.05  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.71  previous:   0.71  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    49  T =     0.078750\n",
            "selected move: eta       : from   0.20 to   0.30\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  1.0  eta :  0.3  gamma :  0.05  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.78  previous:   0.71  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    50  T =     0.078750\n",
            "selected move: max_depth : from  15.00 to  20.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  1.0  eta :  0.3  gamma :  0.05  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.81  previous:   0.78  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    51  T =     0.066937\n",
            "selected move: subsample : from   0.90 to   0.80\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: max_depth : from  20.00 to  25.00\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  1.0  eta :  0.3  gamma :  0.05  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.82  previous:   0.81  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    52  T =     0.066937\n",
            "selected move: gamma     : from   0.05 to   0.00\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  1.0  eta :  0.3  gamma :  0.0  scale_pos_weight :  400  \n",
            "\n",
            "    F-Score:   0.82  previous:   0.82  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    53  T =     0.066937\n",
            "selected move: subsample : from   0.90 to   0.80\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: gamma     : from   0.00 to   0.05\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: scale_pos_weight: from 400.00 to 300.00\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  1.0  eta :  0.3  gamma :  0.0  scale_pos_weight :  300  \n",
            "\n",
            "    F-Score:   0.83  previous:   0.82  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    54  T =     0.066937\n",
            "selected move: eta       : from   0.30 to   0.20\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  1.0  eta :  0.2  gamma :  0.0  scale_pos_weight :  300  \n",
            "\n",
            "    F-Score:   0.78  previous:   0.83  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0538  threshold: 0.3519  random number: 0.3956 -> rejected\n",
            "\n",
            "Iteration =    55  T =     0.066937\n",
            "selected move: subsample : from   0.90 to   1.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: scale_pos_weight: from 300.00 to  50.00\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  1.0  eta :  0.3  gamma :  0.0  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.83  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    56  T =     0.056897\n",
            "selected move: max_depth : from  25.00 to  20.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  1.0  eta :  0.3  gamma :  0.0  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.88  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0123  threshold: 0.7542  random number: 0.8909 -> rejected\n",
            "\n",
            "Iteration =    57  T =     0.056897\n",
            "selected move: gamma     : from   0.00 to   0.05\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  1.0  eta :  0.3  gamma :  0.05  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.88  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0035  threshold: 0.9226  random number: 0.9528 -> rejected\n",
            "\n",
            "Iteration =    58  T =     0.056897\n",
            "selected move: gamma     : from   0.05 to   0.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: colsample_bytree: from   1.00 to   0.90\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.9  eta :  0.3  gamma :  0.0  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.88  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0038  threshold: 0.9172  random number: 0.0737 -> accepted\n",
            "\n",
            "Iteration =    59  T =     0.056897\n",
            "selected move: max_depth : from  25.00 to  20.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.9  eta :  0.3  gamma :  0.0  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.88  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0050  threshold: 0.8930  random number: 0.9994 -> rejected\n",
            "\n",
            "Iteration =    60  T =     0.056897\n",
            "selected move: gamma     : from   0.00 to   0.05\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.9  eta :  0.3  gamma :  0.05  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.88  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0020  threshold: 0.9553  random number: 0.4013 -> accepted\n",
            "\n",
            "Iteration =    61  T =     0.048362\n",
            "selected move: subsample : from   0.90 to   1.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: scale_pos_weight: from  50.00 to  40.00\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.9  eta :  0.3  gamma :  0.05  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.88  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    62  T =     0.048362\n",
            "selected move: gamma     : from   0.05 to   0.10\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.9  eta :  0.3  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0026  threshold: 0.9331  random number: 0.3347 -> accepted\n",
            "\n",
            "Iteration =    63  T =     0.048362\n",
            "selected move: max_depth : from  25.00 to  20.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.9  eta :  0.3  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0053  threshold: 0.8679  random number: 0.4589 -> accepted\n",
            "\n",
            "Iteration =    64  T =     0.048362\n",
            "selected move: eta       : from   0.30 to   0.40\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.9  eta :  0.4  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.88  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    65  T =     0.048362\n",
            "selected move: eta       : from   0.40 to   0.30\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: gamma     : from   0.10 to   0.05\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.9  eta :  0.4  gamma :  0.05  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0038  threshold: 0.9026  random number: 0.2949 -> accepted\n",
            "\n",
            "Iteration =    66  T =     0.041108\n",
            "selected move: max_depth : from  20.00 to  25.00\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.9  eta :  0.4  gamma :  0.05  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0053  threshold: 0.8449  random number: 0.9430 -> rejected\n",
            "\n",
            "Iteration =    67  T =     0.041108\n",
            "selected move: colsample_bytree: from   0.90 to   1.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  1.0  eta :  0.4  gamma :  0.05  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0028  threshold: 0.9158  random number: 0.5728 -> accepted\n",
            "\n",
            "Iteration =    68  T =     0.041108\n",
            "selected move: eta       : from   0.40 to   0.30\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  1.0  eta :  0.3  gamma :  0.05  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0130  threshold: 0.6635  random number: 0.8649 -> rejected\n",
            "\n",
            "Iteration =    69  T =     0.041108\n",
            "selected move: subsample : from   0.90 to   0.80\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: eta       : from   0.40 to   0.30\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: gamma     : from   0.05 to   0.10\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  1.0  eta :  0.4  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.89  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    70  T =     0.041108\n",
            "selected move: eta       : from   0.40 to   0.30\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  1.0  eta :  0.3  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0093  threshold: 0.7463  random number: 0.3062 -> accepted\n",
            "\n",
            "Iteration =    71  T =     0.034942\n",
            "selected move: max_depth : from  20.00 to  25.00\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  1.0  eta :  0.3  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.88  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    72  T =     0.034942\n",
            "selected move: eta       : from   0.30 to   0.20\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  1.0  eta :  0.2  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.88  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0076  threshold: 0.7529  random number: 0.5100 -> accepted\n",
            "\n",
            "Iteration =    73  T =     0.034942\n",
            "selected move: max_depth : from  25.00 to  20.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  1.0  eta :  0.2  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.86  previous:   0.88  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0173  threshold: 0.5252  random number: 0.8661 -> rejected\n",
            "\n",
            "Iteration =    74  T =     0.034942\n",
            "selected move: scale_pos_weight: from  40.00 to  50.00\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  1.0  eta :  0.2  gamma :  0.1  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.88  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0098  threshold: 0.6950  random number: 0.7437 -> rejected\n",
            "\n",
            "Iteration =    75  T =     0.034942\n",
            "selected move: max_depth : from  25.00 to  20.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: colsample_bytree: from   1.00 to   0.90\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.9  eta :  0.2  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.88  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0010  threshold: 0.9629  random number: 0.4698 -> accepted\n",
            "\n",
            "Iteration =    76  T =     0.029700\n",
            "selected move: eta       : from   0.20 to   0.10\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.9  eta :  0.1  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.81  previous:   0.88  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0635  threshold: 0.0620  random number: 0.2287 -> rejected\n",
            "\n",
            "Iteration =    77  T =     0.029700\n",
            "selected move: subsample : from   0.90 to   1.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: max_depth : from  25.00 to  20.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.9  eta :  0.2  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.86  previous:   0.88  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0162  threshold: 0.4924  random number: 0.0967 -> accepted\n",
            "\n",
            "Iteration =    78  T =     0.029700\n",
            "selected move: subsample : from   0.90 to   1.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: colsample_bytree: from   0.90 to   1.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: max_depth : from  20.00 to  15.00\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.9  eta :  0.2  gamma :  0.1  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.84  previous:   0.86  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0177  threshold: 0.4618  random number: 0.1635 -> accepted\n",
            "\n",
            "Iteration =    79  T =     0.029700\n",
            "selected move: gamma     : from   0.10 to   0.15\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.9  eta :  0.2  gamma :  0.15  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.84  previous:   0.84  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    80  T =     0.029700\n",
            "selected move: scale_pos_weight: from  40.00 to  30.00\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.9  eta :  0.2  gamma :  0.15  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.85  previous:   0.84  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    81  T =     0.025245\n",
            "selected move: max_depth : from  15.00 to  20.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.9  eta :  0.2  gamma :  0.15  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.85  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    82  T =     0.025245\n",
            "selected move: eta       : from   0.20 to   0.30\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.9  eta :  0.3  gamma :  0.15  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.87  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    83  T =     0.025245\n",
            "selected move: eta       : from   0.30 to   0.20\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: colsample_bytree: from   0.90 to   0.80\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  gamma :  0.15  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0073  threshold: 0.6862  random number: 0.0942 -> accepted\n",
            "\n",
            "Iteration =    84  T =     0.025245\n",
            "selected move: subsample : from   0.90 to   1.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: gamma     : from   0.15 to   0.20\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  gamma :  0.2  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.88  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    85  T =     0.025245\n",
            "selected move: gamma     : from   0.20 to   0.15\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: colsample_bytree: from   0.80 to   0.70\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.3  gamma :  0.2  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0085  threshold: 0.6455  random number: 0.8721 -> rejected\n",
            "\n",
            "Iteration =    86  T =     0.021459\n",
            "selected move: gamma     : from   0.20 to   0.15\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: subsample : from   0.90 to   1.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: max_depth : from  20.00 to  15.00\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  gamma :  0.2  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0164  threshold: 0.3703  random number: 0.6572 -> rejected\n",
            "\n",
            "Iteration =    87  T =     0.021459\n",
            "selected move: subsample : from   0.90 to   1.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: scale_pos_weight: from  30.00 to  40.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  gamma :  0.2  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0122  threshold: 0.4769  random number: 0.5908 -> rejected\n",
            "\n",
            "Iteration =    88  T =     0.021459\n",
            "selected move: max_depth : from  20.00 to  15.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: subsample : from   0.90 to   1.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: scale_pos_weight: from  30.00 to  40.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: max_depth : from  20.00 to  25.00\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  gamma :  0.2  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0032  threshold: 0.8215  random number: 0.3163 -> accepted\n",
            "\n",
            "Iteration =    89  T =     0.021459\n",
            "selected move: max_depth : from  25.00 to  20.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: subsample : from   0.90 to   1.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: eta       : from   0.30 to   0.40\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.8  eta :  0.4  gamma :  0.2  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.89  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    90  T =     0.021459\n",
            "selected move: colsample_bytree: from   0.80 to   0.70\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.2  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.89  best so far:   0.89\n",
            "    Local improvement\n",
            "\n",
            "Iteration =    91  T =     0.018240\n",
            "selected move: scale_pos_weight: from  30.00 to  40.00\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.2  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.89  best so far:   0.89\n",
            "    Worse result. F-Score change:  -0.0117  threshold: 0.4339  random number: 0.8193 -> rejected\n",
            "\n",
            "Iteration =    92  T =     0.018240\n",
            "selected move: scale_pos_weight: from  40.00 to  30.00\n",
            "\n",
            "Combination revisited - searching again\n",
            "selected move: gamma     : from   0.20 to   0.15\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.15  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.90  previous:   0.89  best so far:   0.89\n",
            "    Local improvement\n",
            "    Global improvement - best f-score updated\n",
            "\n",
            "Iteration =    93  T =     0.018240\n",
            "selected move: max_depth : from  25.00 to  20.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.15  scale_pos_weight :  30  \n",
            "\n",
            "    F-Score:   0.89  previous:   0.90  best so far:   0.90\n",
            "    Worse result. F-Score change:  -0.0054  threshold: 0.6792  random number: 0.0303 -> accepted\n",
            "\n",
            "Iteration =    94  T =     0.018240\n",
            "selected move: scale_pos_weight: from  30.00 to  40.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.15  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.89  best so far:   0.90\n",
            "    Worse result. F-Score change:  -0.0100  threshold: 0.4914  random number: 0.3112 -> accepted\n",
            "\n",
            "Iteration =    95  T =     0.018240\n",
            "selected move: scale_pos_weight: from  40.00 to  50.00\n",
            "Parameters:\n",
            "max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.15  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.88  best so far:   0.90\n",
            "    Worse result. F-Score change:  -0.0013  threshold: 0.9147  random number: 0.3687 -> accepted\n",
            "\n",
            "Iteration =    96  T =     0.015504\n",
            "selected move: max_depth : from  20.00 to  15.00\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.15  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.88  previous:   0.88  best so far:   0.90\n",
            "    Worse result. F-Score change:  -0.0017  threshold: 0.8671  random number: 0.8597 -> accepted\n",
            "\n",
            "Iteration =    97  T =     0.015504\n",
            "selected move: max_depth : from  15.00 to  10.00\n",
            "Parameters:\n",
            "max_depth :  10  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.15  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.85  previous:   0.88  best so far:   0.90\n",
            "    Worse result. F-Score change:  -0.0289  threshold: 0.0884  random number: 0.4783 -> rejected\n",
            "\n",
            "Iteration =    98  T =     0.015504\n",
            "selected move: colsample_bytree: from   0.70 to   0.60\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.6  eta :  0.4  gamma :  0.15  scale_pos_weight :  50  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.88  best so far:   0.90\n",
            "    Worse result. F-Score change:  -0.0078  threshold: 0.5189  random number: 0.7315 -> rejected\n",
            "\n",
            "Iteration =    99  T =     0.015504\n",
            "selected move: scale_pos_weight: from  50.00 to  40.00\n",
            "Parameters:\n",
            "max_depth :  15  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.15  scale_pos_weight :  40  \n",
            "\n",
            "    F-Score:   0.87  previous:   0.88  best so far:   0.90\n",
            "    Worse result. F-Score change:  -0.0065  threshold: 0.5812  random number: 0.9044 -> rejected\n",
            "\n",
            "   6.4 minutes process time\n",
            "\n",
            "Best variable parameters found:\n",
            "\n",
            "{'max_depth': 25, 'subsample': 0.9, 'colsample_bytree': 0.7, 'eta': 0.4, 'gamma': 0.15, 'scale_pos_weight': 30}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nBest parameters found:\\n')  \n",
        "print(best_params)\n",
        "\n",
        "print('\\nEvaluation on the test dataset\\n')  \n",
        "\n",
        "best_f_score,best_model=do_train(best_params, param, dtrain,'train',trainY,dtest,'test',testY,print_conf_matrix=True)\n",
        "\n",
        "\n",
        "print('\\nF-score on the test dataset: {:6.2f}'.format(best_f_score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPFlmyrYlpu8",
        "outputId": "c2f6d7b9-a822-4c9b-89d0-be2a16fdae9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best parameters found:\n",
            "\n",
            "{'max_depth': 25, 'subsample': 0.9, 'colsample_bytree': 0.7, 'eta': 0.4, 'gamma': 0.15, 'scale_pos_weight': 30}\n",
            "\n",
            "Evaluation on the test dataset\n",
            "\n",
            "Parameters:\n",
            "max_depth :  25  subsample :  0.9  colsample_bytree :  0.7  eta :  0.4  gamma :  0.15  scale_pos_weight :  30  \n",
            "\n",
            "\n",
            "confusion matrix\n",
            "----------------\n",
            "tn:  1286 fp:   239\n",
            "fn:    74 tp:  1343\n",
            "\n",
            "F-score on the test dataset:   0.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y = delirium_dataset_encoded[\"Delirium\"].values\n",
        "#X=delirium_dataset_encoded.drop([\"Delirium\"], axis=1)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, random_state=42)\n",
        "\n",
        "clf_xgb = xgb.XGBClassifier(colsample_bytree= 0.6,\n",
        "          gamma=0.15,\n",
        "          scale_pos_weight= 30,\n",
        "          eta= 0.4,\n",
        "          max_depth= 25,\n",
        "          min_child_weight=17,\n",
        "          subsample= 0.9,objective='binary:logistic',\n",
        "                            eval_metric=\"logloss\", ## this avoids a warning...\n",
        "                            seed=42, \n",
        "                            use_label_encoder=False)"
      ],
      "metadata": {
        "id": "Tgt5tYnolpsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lPjTDWglpo6",
        "outputId": "5bbba88d-b407-4c98-a35a-f2122eb6860a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(colsample_bytree=0.6, eta=0.4, eval_metric='logloss', gamma=0.15,\n",
              "              max_depth=25, min_child_weight=17, scale_pos_weight=30, seed=42,\n",
              "              subsample=0.9, use_label_encoder=False)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prd=clf_xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "IbGrpv9Vlplx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix # creates a confusion matrix\n",
        "from sklearn.metrics import plot_confusion_matrix # draws a confusion matrix\n",
        "plot_confusion_matrix(clf_xgb, X_test, y_test, display_labels=[\"No Delirium\", \"Delirium\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "YMLkhj-79R3e",
        "outputId": "0b9798ef-f45c-4ca6-e293-4004a57b11fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f56546983d0>"
            ]
          },
          "metadata": {},
          "execution_count": 149
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "print(classification_report(y_test, prd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6ItJf4z9WHE",
        "outputId": "43bc6f80-0472-40e8-d198-96bc21fb2206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.78      0.86      1905\n",
            "           1       0.81      0.97      0.88      1772\n",
            "\n",
            "    accuracy                           0.87      3677\n",
            "   macro avg       0.88      0.88      0.87      3677\n",
            "weighted avg       0.89      0.87      0.87      3677\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix # creates a confusion matrix\n",
        "from sklearn.metrics import plot_confusion_matrix # draws a confusion matrix\n",
        "plot_confusion_matrix(clf_xgb, X_test, y_test, display_labels=[\"No Delirium\", \"Delirium\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "tj_oti2Z7aGw",
        "outputId": "a7efae5f-4968-4dc7-eb50-2e1d9c40e72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5654711b10>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "print(classification_report(y_test, prd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7AgaZed7hRS",
        "outputId": "ecaf2c61-74d3-43c1-b40a-5bf70394c1bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93      1932\n",
            "           1       0.28      0.18      0.22       230\n",
            "\n",
            "    accuracy                           0.86      2162\n",
            "   macro avg       0.59      0.56      0.57      2162\n",
            "weighted avg       0.84      0.86      0.85      2162\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix # creates a confusion matrix\n",
        "from sklearn.metrics import plot_confusion_matrix # draws a confusion matrix\n",
        "plot_confusion_matrix(clf_xgb, X_test, y_test, display_labels=[\"No Delirium\", \"Delirium\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "IvIA4XcGlpis",
        "outputId": "90d2e8f9-f43d-4945-c050-117035f63a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f56549126d0>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "print(classification_report(y_test, prd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8nP4ykHoOVS",
        "outputId": "7cb5f7f6-8520-4843-e0a5-fb8d08cdd41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.87      0.89      1932\n",
            "           1       0.22      0.31      0.26       230\n",
            "\n",
            "    accuracy                           0.81      2162\n",
            "   macro avg       0.57      0.59      0.57      2162\n",
            "weighted avg       0.84      0.81      0.82      2162\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = pd.crosstab(y_test,prd)\n",
        "err_metric(confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmM0D_xKofsD",
        "outputId": "2b69d9e3-f2a6-4fe0-ddad-7159999ff91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision value of the model:  0.8060122123062471\n",
            "Accuracy of the model:  0.8724503671471309\n",
            "Recall of the model:  0.9683972911963883\n",
            "Specificity of the model:  0.7832020997375329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Random Forest Classifier on undersampled data'''\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "rfmodel = RandomForestClassifier()\n",
        "rfmodel.fit(xtrain,ytrain)\n",
        "print('model')\n",
        "print(rfmodel)\n",
        "\n",
        "ypredrf = rfmodel.predict(xtest)\n",
        "print('confusion matrix')\n",
        "print(metrics.confusion_matrix(ytest, ypredrf))\n",
        "print('classification report')\n",
        "print(metrics.classification_report(ytest, ypredrf))\n",
        "print('Accuracy : %f' % (metrics.accuracy_score(ytest, ypredrf)))\n",
        "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, ypredrf)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COviPZD6offn",
        "outputId": "a6902372-7031-4f55-d4da-d6538c748c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "RandomForestClassifier()\n",
            "confusion matrix\n",
            "[[117 115]\n",
            " [ 52 230]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.50      0.58       232\n",
            "           1       0.67      0.82      0.73       282\n",
            "\n",
            "    accuracy                           0.68       514\n",
            "   macro avg       0.68      0.66      0.66       514\n",
            "weighted avg       0.68      0.68      0.67       514\n",
            "\n",
            "Accuracy : 0.675097\n",
            "Area under the curve : 0.659957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_xgb = xgb.XGBClassifier(colsample_bytree= 0.6,\n",
        "          gamma=0.05,\n",
        "          scale_pos_weight= 40,\n",
        "          eta= 0.1,\n",
        "          max_depth= 25,\n",
        "          min_child_weight=17,\n",
        "          subsample= 0.5,objective='binary:logistic',\n",
        "                            eval_metric=\"logloss\", ## this avoids a warning...\n",
        "                            seed=42, \n",
        "                            use_label_encoder=False)"
      ],
      "metadata": {
        "id": "VFlhjZGzofcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_xgb.fit(xtrain,ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0SFQV0yofZs",
        "outputId": "8a05ce2d-591c-4ee6-df33-d792e024284c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(colsample_bytree=0.6, eta=0.1, eval_metric='logloss', gamma=0.05,\n",
              "              max_depth=25, min_child_weight=17, scale_pos_weight=40, seed=42,\n",
              "              subsample=0.5, use_label_encoder=False)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('model')\n",
        "print(clf_xgb)\n",
        "\n",
        "ypredxgb = clf_xgb.predict(xtest)\n",
        "print('confusion matrix')\n",
        "print(metrics.confusion_matrix(ytest, ypredxgb))\n",
        "print('classification report')\n",
        "print(metrics.classification_report(ytest, ypredxgb))\n",
        "print('Accuracy : %f' % (metrics.accuracy_score(ytest, ypredxgb)))\n",
        "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, ypredxgb)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAycllCszpmv",
        "outputId": "1baa9943-1ff8-4262-e28b-914a8f13d693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "XGBClassifier(colsample_bytree=0.6, eta=0.1, eval_metric='logloss', gamma=0.05,\n",
            "              max_depth=25, min_child_weight=17, scale_pos_weight=40, seed=42,\n",
            "              subsample=0.5, use_label_encoder=False)\n",
            "confusion matrix\n",
            "[[1534  776]\n",
            " [  56 1446]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.66      0.79      2310\n",
            "           1       0.65      0.96      0.78      1502\n",
            "\n",
            "    accuracy                           0.78      3812\n",
            "   macro avg       0.81      0.81      0.78      3812\n",
            "weighted avg       0.84      0.78      0.78      3812\n",
            "\n",
            "Accuracy : 0.781742\n",
            "Area under the curve : 0.813393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('model')\n",
        "print(clf_xgb)\n",
        "\n",
        "ypredxgb = clf_xgb.predict(xtest)\n",
        "print('confusion matrix')\n",
        "print(metrics.confusion_matrix(ytest, ypredxgb))\n",
        "print('classification report')\n",
        "print(metrics.classification_report(ytest, ypredxgb))\n",
        "print('Accuracy : %f' % (metrics.accuracy_score(ytest, ypredxgb)))\n",
        "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, ypredxgb)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEcjZTN_vpba",
        "outputId": "18e6ed85-b8c7-49b3-c0dc-8c763196fd7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "XGBClassifier(colsample_bytree=0.6, eta=0.1, eval_metric='logloss', gamma=0.05,\n",
            "              max_depth=25, min_child_weight=17, scale_pos_weight=40, seed=42,\n",
            "              subsample=0.5, use_label_encoder=False)\n",
            "confusion matrix\n",
            "[[1797  526]\n",
            " [ 116  473]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.77      0.85      2323\n",
            "           1       0.47      0.80      0.60       589\n",
            "\n",
            "    accuracy                           0.78      2912\n",
            "   macro avg       0.71      0.79      0.72      2912\n",
            "weighted avg       0.85      0.78      0.80      2912\n",
            "\n",
            "Accuracy : 0.779533\n",
            "Area under the curve : 0.788312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('model')\n",
        "print(clf_xgb)\n",
        "\n",
        "ypredxgb = clf_xgb.predict(xtest)\n",
        "print('confusion matrix')\n",
        "print(metrics.confusion_matrix(ytest, ypredxgb))\n",
        "print('classification report')\n",
        "print(metrics.classification_report(ytest, ypredxgb))\n",
        "print('Accuracy : %f' % (metrics.accuracy_score(ytest, ypredxgb)))\n",
        "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, ypredxgb)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVK-mLBDofWk",
        "outputId": "aa894ee7-4492-413d-c3f0-772f25933986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "XGBClassifier(colsample_bytree=0.6, eta=0.1, eval_metric='logloss', gamma=0.05,\n",
            "              max_depth=25, min_child_weight=17, scale_pos_weight=40, seed=42,\n",
            "              subsample=0.5, use_label_encoder=False)\n",
            "confusion matrix\n",
            "[[  5 227]\n",
            " [  0 282]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.02      0.04       232\n",
            "           1       0.55      1.00      0.71       282\n",
            "\n",
            "    accuracy                           0.56       514\n",
            "   macro avg       0.78      0.51      0.38       514\n",
            "weighted avg       0.76      0.56      0.41       514\n",
            "\n",
            "Accuracy : 0.558366\n",
            "Area under the curve : 0.510776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix # creates a confusion matrix\n",
        "from sklearn.metrics import plot_confusion_matrix # draws a confusion matrix\n",
        "plot_confusion_matrix(rfmodel, X_test, y_test, display_labels=[\"No Delirium\", \"Delirium\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "5g6wgLVt8kS2",
        "outputId": "296e6f00-d43e-4c60-c8ec-96aff7ad630b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5657d2bed0>"
            ]
          },
          "metadata": {},
          "execution_count": 145
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Random Forest Classifier on resampled data'''\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "rfmodel = RandomForestClassifier()\n",
        "rfmodel.fit(xtrain,ytrain)\n",
        "print('model')\n",
        "print(rfmodel)\n",
        "\n",
        "ypredrf = rfmodel.predict(xtest)\n",
        "print('confusion matrix')\n",
        "print(metrics.confusion_matrix(ytest, ypredrf))\n",
        "print('classification report')\n",
        "print(metrics.classification_report(ytest, ypredrf))\n",
        "print('Accuracy : %f' % (metrics.accuracy_score(ytest, ypredrf)))\n",
        "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, ypredrf)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viKWPYgS8cVS",
        "outputId": "c5fe693e-a734-49cf-989a-1c3814bd1335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "RandomForestClassifier()\n",
            "confusion matrix\n",
            "[[2245   58]\n",
            " [ 180 1929]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      2303\n",
            "           1       0.97      0.91      0.94      2109\n",
            "\n",
            "    accuracy                           0.95      4412\n",
            "   macro avg       0.95      0.94      0.95      4412\n",
            "weighted avg       0.95      0.95      0.95      4412\n",
            "\n",
            "Accuracy : 0.946056\n",
            "Area under the curve : 0.944733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Random Forest Classifier on resampled data'''\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "rfmodel = RandomForestClassifier()\n",
        "rfmodel.fit(xtrain,ytrain)\n",
        "print('model')\n",
        "print(rfmodel)\n",
        "\n",
        "ypredrf = rfmodel.predict(xtest)\n",
        "print('confusion matrix')\n",
        "print(metrics.confusion_matrix(ytest, ypredrf))\n",
        "print('classification report')\n",
        "print(metrics.classification_report(ytest, ypredrf))\n",
        "print('Accuracy : %f' % (metrics.accuracy_score(ytest, ypredrf)))\n",
        "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, ypredrf)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1d84i0Vz_gt",
        "outputId": "0d9f1a21-a590-405c-d0bb-f4cc1564e3ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "RandomForestClassifier()\n",
            "confusion matrix\n",
            "[[2237   66]\n",
            " [ 177 1932]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      2303\n",
            "           1       0.97      0.92      0.94      2109\n",
            "\n",
            "    accuracy                           0.94      4412\n",
            "   macro avg       0.95      0.94      0.94      4412\n",
            "weighted avg       0.95      0.94      0.94      4412\n",
            "\n",
            "Accuracy : 0.944923\n",
            "Area under the curve : 0.943708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Random Forest Classifier on resampled data'''\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "rfmodel = RandomForestClassifier()\n",
        "rfmodel.fit(xtrain,ytrain)\n",
        "print('model')\n",
        "print(rfmodel)\n",
        "\n",
        "ypredrf = rfmodel.predict(xtest)\n",
        "print('confusion matrix')\n",
        "print(metrics.confusion_matrix(ytest, ypredrf))\n",
        "print('classification report')\n",
        "print(metrics.classification_report(ytest, ypredrf))\n",
        "print('Accuracy : %f' % (metrics.accuracy_score(ytest, ypredrf)))\n",
        "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, ypredrf)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfpjtN-DzevZ",
        "outputId": "01981a3f-de80-421a-e68b-e3b0dd0e5a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "RandomForestClassifier()\n",
            "confusion matrix\n",
            "[[2277   33]\n",
            " [ 222 1280]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.99      0.95      2310\n",
            "           1       0.97      0.85      0.91      1502\n",
            "\n",
            "    accuracy                           0.93      3812\n",
            "   macro avg       0.94      0.92      0.93      3812\n",
            "weighted avg       0.94      0.93      0.93      3812\n",
            "\n",
            "Accuracy : 0.933106\n",
            "Area under the curve : 0.918956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Random Forest Classifier on resampled data'''\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "rfmodel = RandomForestClassifier()\n",
        "rfmodel.fit(xtrain,ytrain)\n",
        "print('model')\n",
        "print(rfmodel)\n",
        "\n",
        "ypredrf = rfmodel.predict(xtest)\n",
        "print('confusion matrix')\n",
        "print(metrics.confusion_matrix(ytest, ypredrf))\n",
        "print('classification report')\n",
        "print(metrics.classification_report(ytest, ypredrf))\n",
        "print('Accuracy : %f' % (metrics.accuracy_score(ytest, ypredrf)))\n",
        "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, ypredrf)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4z1-9s1u7Y8",
        "outputId": "41575456-17c1-4823-9a75-1be8d21b5e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "RandomForestClassifier()\n",
            "confusion matrix\n",
            "[[2322    1]\n",
            " [ 388  201]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.92      2323\n",
            "           1       1.00      0.34      0.51       589\n",
            "\n",
            "    accuracy                           0.87      2912\n",
            "   macro avg       0.93      0.67      0.72      2912\n",
            "weighted avg       0.88      0.87      0.84      2912\n",
            "\n",
            "Accuracy : 0.866415\n",
            "Area under the curve : 0.670413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning Random Forest Hyperparameters "
      ],
      "metadata": {
        "id": "Sc_CMs2DAsZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV"
      ],
      "metadata": {
        "id": "oqd4ASdVBB7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Random Forest Classifier on resampled data'''\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "rfmodel = RandomForestClassifier()\n",
        "rfmodel.fit(xtrain,ytrain)\n",
        "print('model')\n",
        "print(rfmodel)\n",
        "\n",
        "ypredrf = rfmodel.predict(xtest)\n",
        "print('confusion matrix')\n",
        "print(metrics.confusion_matrix(ytest, ypredrf))\n",
        "print('classification report')\n",
        "print(metrics.classification_report(ytest, ypredrf))\n",
        "print('Accuracy : %f' % (metrics.accuracy_score(ytest, ypredrf)))\n",
        "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, ypredrf)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXtpqdA5GMer",
        "outputId": "2bbe3cc7-d40c-423c-f98b-83a2031d7cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "RandomForestClassifier()\n",
            "confusion matrix\n",
            "[[2295    0]\n",
            " [ 293    6]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      2295\n",
            "           1       1.00      0.02      0.04       299\n",
            "\n",
            "    accuracy                           0.89      2594\n",
            "   macro avg       0.94      0.51      0.49      2594\n",
            "weighted avg       0.90      0.89      0.84      2594\n",
            "\n",
            "Accuracy : 0.887047\n",
            "Area under the curve : 0.510033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#UNDERSAMPLED DATASET\n",
        "\n",
        "'''Random Forest Classifier on resampled data'''\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "rfmodel = RandomForestClassifier()\n",
        "rfmodel.fit(xtrain,ytrain)\n",
        "print('model')\n",
        "print(rfmodel)\n",
        "\n",
        "ypredrf = rfmodel.predict(xtest)\n",
        "print('confusion matrix')\n",
        "print(metrics.confusion_matrix(ytest, ypredrf))\n",
        "print('classification report')\n",
        "print(metrics.classification_report(ytest, ypredrf))\n",
        "print('Accuracy : %f' % (metrics.accuracy_score(ytest, ypredrf)))\n",
        "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, ypredrf)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmBW5SAnGhVO",
        "outputId": "db2b86ef-471c-4d0e-cf17-cc9eb6886a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "RandomForestClassifier()\n",
            "confusion matrix\n",
            "[[ 88 151]\n",
            " [ 48 227]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.37      0.47       239\n",
            "           1       0.60      0.83      0.70       275\n",
            "\n",
            "    accuracy                           0.61       514\n",
            "   macro avg       0.62      0.60      0.58       514\n",
            "weighted avg       0.62      0.61      0.59       514\n",
            "\n",
            "Accuracy : 0.612840\n",
            "Area under the curve : 0.596828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OVERSAMPLED DATASET\n",
        "\n",
        "'''Random Forest Classifier on resampled data'''\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "rfmodel = RandomForestClassifier()\n",
        "rfmodel.fit(xtrain,ytrain)\n",
        "print('model')\n",
        "print(rfmodel)\n",
        "\n",
        "ypredrf = rfmodel.predict(xtest)\n",
        "print('confusion matrix')\n",
        "print(metrics.confusion_matrix(ytest, ypredrf))\n",
        "print('classification report')\n",
        "print(metrics.classification_report(ytest, ypredrf))\n",
        "print('Accuracy : %f' % (metrics.accuracy_score(ytest, ypredrf)))\n",
        "print('Area under the curve : %f' % (metrics.roc_auc_score(ytest, ypredrf)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSZC6QNDG1zf",
        "outputId": "b243d7b5-1003-45c4-d069-a59068c8ffcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "RandomForestClassifier()\n",
            "confusion matrix\n",
            "[[2235   68]\n",
            " [ 166 1943]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      2303\n",
            "           1       0.97      0.92      0.94      2109\n",
            "\n",
            "    accuracy                           0.95      4412\n",
            "   macro avg       0.95      0.95      0.95      4412\n",
            "weighted avg       0.95      0.95      0.95      4412\n",
            "\n",
            "Accuracy : 0.946963\n",
            "Area under the curve : 0.945882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = pd.crosstab(ytest,ypredrf)\n",
        "err_metric(confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nk-dO-XHCgP",
        "outputId": "4f97663e-fe7a-44ae-8217-7517a9745f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision value of the model:  0.966185977125808\n",
            "Accuracy of the model:  0.9469628286491387\n",
            "Recall of the model:  0.9212897107633949\n",
            "Specificity of the model:  0.9704732957012592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting values for the parameters\n",
        "n_estimators = [100, 300, 500, 800, 1200]\n",
        "max_depth = [5, 10, 15, 25, 30]\n",
        "min_samples_split = [2, 5, 10, 15, 100]\n",
        "min_samples_leaf = [1, 2, 5, 10]\n",
        "rf = RandomForestClassifier()\n",
        "#Creating a dictionary for the hyper parameters\n",
        "hyper_rf = dict(n_estimators = n_estimators, max_depth = max_depth, \n",
        "              min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)\n",
        "\n",
        "#Applying GridSearchCV to get the best value for hyperparameters\n",
        "gridrf = GridSearchCV(rf, hyper_rf, cv = 3, verbose = 1, n_jobs = -1)\n",
        "bestrf = gridrf.fit(xtrain, ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqktXD-8e6aC",
        "outputId": "378782d7-be18-47e1-d332-73b2444e062d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
          ]
        }
      ]
    }
  ]
}